{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c328e949-3127-4580-90d1-23000008be5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7697 images belonging to 355 classes.\n",
      "Found 3560 images belonging to 355 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17225924/17225924 [==============================] - 2s 0us/step\n",
      "Epoch 1/1000\n",
      "240/240 [==============================] - 77s 296ms/step - loss: 4.4326 - accuracy: 0.1410 - val_loss: 2.8688 - val_accuracy: 0.3224\n",
      "Epoch 2/1000\n",
      "240/240 [==============================] - 67s 280ms/step - loss: 2.2677 - accuracy: 0.4309 - val_loss: 2.2874 - val_accuracy: 0.4268\n",
      "Epoch 3/1000\n",
      "240/240 [==============================] - 67s 279ms/step - loss: 1.6242 - accuracy: 0.5714 - val_loss: 2.0824 - val_accuracy: 0.4648\n",
      "Epoch 4/1000\n",
      "240/240 [==============================] - 67s 281ms/step - loss: 1.2759 - accuracy: 0.6519 - val_loss: 2.0335 - val_accuracy: 0.4848\n",
      "Epoch 5/1000\n",
      "240/240 [==============================] - 67s 281ms/step - loss: 1.0231 - accuracy: 0.7164 - val_loss: 1.9556 - val_accuracy: 0.5068\n",
      "Epoch 6/1000\n",
      "240/240 [==============================] - 67s 281ms/step - loss: 0.8376 - accuracy: 0.7667 - val_loss: 1.9675 - val_accuracy: 0.5073\n",
      "Epoch 7/1000\n",
      "240/240 [==============================] - 68s 281ms/step - loss: 0.6843 - accuracy: 0.8076 - val_loss: 1.9821 - val_accuracy: 0.5141\n",
      "Epoch 8/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.5845 - accuracy: 0.8326 - val_loss: 2.0184 - val_accuracy: 0.5160\n",
      "Epoch 9/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.5027 - accuracy: 0.8658 - val_loss: 2.0053 - val_accuracy: 0.5186\n",
      "Epoch 10/1000\n",
      "240/240 [==============================] - 67s 281ms/step - loss: 0.4435 - accuracy: 0.8831 - val_loss: 2.0220 - val_accuracy: 0.5360\n",
      "Epoch 11/1000\n",
      "240/240 [==============================] - 67s 281ms/step - loss: 0.3956 - accuracy: 0.8922 - val_loss: 2.0245 - val_accuracy: 0.5377\n",
      "Epoch 12/1000\n",
      "240/240 [==============================] - 67s 280ms/step - loss: 0.3450 - accuracy: 0.9122 - val_loss: 2.0289 - val_accuracy: 0.5405\n",
      "Epoch 13/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.3130 - accuracy: 0.9183 - val_loss: 2.0896 - val_accuracy: 0.5372\n",
      "Epoch 14/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.2835 - accuracy: 0.9281 - val_loss: 2.0412 - val_accuracy: 0.5476\n",
      "Epoch 15/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.2780 - accuracy: 0.9311 - val_loss: 2.0859 - val_accuracy: 0.5400\n",
      "Epoch 16/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.2481 - accuracy: 0.9382 - val_loss: 2.0662 - val_accuracy: 0.5535\n",
      "Epoch 17/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.2409 - accuracy: 0.9379 - val_loss: 2.0696 - val_accuracy: 0.5498\n",
      "Epoch 18/1000\n",
      "240/240 [==============================] - 68s 281ms/step - loss: 0.2272 - accuracy: 0.9438 - val_loss: 2.0763 - val_accuracy: 0.5569\n",
      "Epoch 19/1000\n",
      "240/240 [==============================] - 67s 281ms/step - loss: 0.2307 - accuracy: 0.9392 - val_loss: 2.0714 - val_accuracy: 0.5541\n",
      "Epoch 20/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.2087 - accuracy: 0.9455 - val_loss: 2.0919 - val_accuracy: 0.5512\n",
      "Epoch 21/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.2046 - accuracy: 0.9477 - val_loss: 2.0461 - val_accuracy: 0.5529\n",
      "Epoch 22/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1947 - accuracy: 0.9476 - val_loss: 2.1021 - val_accuracy: 0.5512\n",
      "Epoch 23/1000\n",
      "240/240 [==============================] - 67s 281ms/step - loss: 0.1967 - accuracy: 0.9504 - val_loss: 2.0886 - val_accuracy: 0.5600\n",
      "Epoch 24/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1870 - accuracy: 0.9545 - val_loss: 2.1325 - val_accuracy: 0.5498\n",
      "Epoch 25/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1740 - accuracy: 0.9554 - val_loss: 2.1459 - val_accuracy: 0.5495\n",
      "Epoch 26/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1777 - accuracy: 0.9538 - val_loss: 2.1327 - val_accuracy: 0.5572\n",
      "Epoch 27/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1624 - accuracy: 0.9573 - val_loss: 2.1586 - val_accuracy: 0.5563\n",
      "Epoch 28/1000\n",
      "240/240 [==============================] - 68s 281ms/step - loss: 0.1647 - accuracy: 0.9575 - val_loss: 2.1462 - val_accuracy: 0.5529\n",
      "Epoch 29/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1588 - accuracy: 0.9584 - val_loss: 2.2018 - val_accuracy: 0.5470\n",
      "Epoch 30/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1572 - accuracy: 0.9596 - val_loss: 2.1270 - val_accuracy: 0.5557\n",
      "Epoch 31/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1572 - accuracy: 0.9594 - val_loss: 2.1639 - val_accuracy: 0.5521\n",
      "Epoch 32/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1582 - accuracy: 0.9583 - val_loss: 2.1773 - val_accuracy: 0.5524\n",
      "Epoch 33/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1579 - accuracy: 0.9581 - val_loss: 2.1731 - val_accuracy: 0.5526\n",
      "Epoch 34/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1481 - accuracy: 0.9601 - val_loss: 2.1995 - val_accuracy: 0.5524\n",
      "Epoch 35/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1480 - accuracy: 0.9606 - val_loss: 2.1695 - val_accuracy: 0.5512\n",
      "Epoch 36/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1448 - accuracy: 0.9618 - val_loss: 2.1464 - val_accuracy: 0.5563\n",
      "Epoch 37/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1424 - accuracy: 0.9611 - val_loss: 2.1941 - val_accuracy: 0.5484\n",
      "Epoch 38/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1443 - accuracy: 0.9611 - val_loss: 2.1781 - val_accuracy: 0.5521\n",
      "Epoch 39/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1293 - accuracy: 0.9640 - val_loss: 2.2006 - val_accuracy: 0.5586\n",
      "Epoch 40/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1352 - accuracy: 0.9628 - val_loss: 2.1773 - val_accuracy: 0.5586\n",
      "Epoch 41/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1318 - accuracy: 0.9652 - val_loss: 2.2135 - val_accuracy: 0.5473\n",
      "Epoch 42/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.1391 - accuracy: 0.9599 - val_loss: 2.2094 - val_accuracy: 0.5510\n",
      "Epoch 43/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.1282 - accuracy: 0.9632 - val_loss: 2.1929 - val_accuracy: 0.5518\n",
      "Epoch 44/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.1333 - accuracy: 0.9633 - val_loss: 2.2140 - val_accuracy: 0.5549\n",
      "Epoch 45/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.1295 - accuracy: 0.9626 - val_loss: 2.1878 - val_accuracy: 0.5538\n",
      "Epoch 46/1000\n",
      "240/240 [==============================] - 70s 290ms/step - loss: 0.1306 - accuracy: 0.9615 - val_loss: 2.1969 - val_accuracy: 0.5465\n",
      "Epoch 47/1000\n",
      "240/240 [==============================] - 70s 290ms/step - loss: 0.1225 - accuracy: 0.9648 - val_loss: 2.2030 - val_accuracy: 0.5495\n",
      "Epoch 48/1000\n",
      "240/240 [==============================] - 69s 289ms/step - loss: 0.1243 - accuracy: 0.9645 - val_loss: 2.2001 - val_accuracy: 0.5510\n",
      "Epoch 49/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1275 - accuracy: 0.9635 - val_loss: 2.1924 - val_accuracy: 0.5586\n",
      "Epoch 50/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.1167 - accuracy: 0.9649 - val_loss: 2.2311 - val_accuracy: 0.5521\n",
      "Epoch 51/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1186 - accuracy: 0.9639 - val_loss: 2.2055 - val_accuracy: 0.5493\n",
      "Epoch 52/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1219 - accuracy: 0.9626 - val_loss: 2.1878 - val_accuracy: 0.5493\n",
      "Epoch 53/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1159 - accuracy: 0.9650 - val_loss: 2.1966 - val_accuracy: 0.5594\n",
      "Epoch 54/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1208 - accuracy: 0.9653 - val_loss: 2.2120 - val_accuracy: 0.5546\n",
      "Epoch 55/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.1247 - accuracy: 0.9643 - val_loss: 2.1838 - val_accuracy: 0.5572\n",
      "Epoch 56/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1144 - accuracy: 0.9654 - val_loss: 2.2082 - val_accuracy: 0.5569\n",
      "Epoch 57/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1174 - accuracy: 0.9656 - val_loss: 2.1841 - val_accuracy: 0.5625\n",
      "Epoch 58/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.1126 - accuracy: 0.9649 - val_loss: 2.2171 - val_accuracy: 0.5572\n",
      "Epoch 59/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1122 - accuracy: 0.9652 - val_loss: 2.2290 - val_accuracy: 0.5521\n",
      "Epoch 60/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1202 - accuracy: 0.9656 - val_loss: 2.1938 - val_accuracy: 0.5484\n",
      "Epoch 61/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1085 - accuracy: 0.9658 - val_loss: 2.2505 - val_accuracy: 0.5484\n",
      "Epoch 62/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1078 - accuracy: 0.9674 - val_loss: 2.2292 - val_accuracy: 0.5512\n",
      "Epoch 63/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1175 - accuracy: 0.9645 - val_loss: 2.1893 - val_accuracy: 0.5614\n",
      "Epoch 64/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1039 - accuracy: 0.9669 - val_loss: 2.2629 - val_accuracy: 0.5495\n",
      "Epoch 65/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1133 - accuracy: 0.9641 - val_loss: 2.2220 - val_accuracy: 0.5560\n",
      "Epoch 66/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1103 - accuracy: 0.9662 - val_loss: 2.2386 - val_accuracy: 0.5546\n",
      "Epoch 67/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1073 - accuracy: 0.9656 - val_loss: 2.1953 - val_accuracy: 0.5633\n",
      "Epoch 68/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1064 - accuracy: 0.9663 - val_loss: 2.2090 - val_accuracy: 0.5591\n",
      "Epoch 69/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1057 - accuracy: 0.9648 - val_loss: 2.2445 - val_accuracy: 0.5490\n",
      "Epoch 70/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1047 - accuracy: 0.9683 - val_loss: 2.2239 - val_accuracy: 0.5563\n",
      "Epoch 71/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1050 - accuracy: 0.9666 - val_loss: 2.2154 - val_accuracy: 0.5549\n",
      "Epoch 72/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1015 - accuracy: 0.9665 - val_loss: 2.2070 - val_accuracy: 0.5633\n",
      "Epoch 73/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1072 - accuracy: 0.9666 - val_loss: 2.2184 - val_accuracy: 0.5619\n",
      "Epoch 74/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1065 - accuracy: 0.9665 - val_loss: 2.1972 - val_accuracy: 0.5577\n",
      "Epoch 75/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1016 - accuracy: 0.9683 - val_loss: 2.2086 - val_accuracy: 0.5569\n",
      "Epoch 76/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1089 - accuracy: 0.9658 - val_loss: 2.1975 - val_accuracy: 0.5605\n",
      "Epoch 77/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0990 - accuracy: 0.9683 - val_loss: 2.1805 - val_accuracy: 0.5560\n",
      "Epoch 78/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0991 - accuracy: 0.9678 - val_loss: 2.2178 - val_accuracy: 0.5549\n",
      "Epoch 79/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.1004 - accuracy: 0.9662 - val_loss: 2.2367 - val_accuracy: 0.5507\n",
      "Epoch 80/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.1018 - accuracy: 0.9670 - val_loss: 2.2063 - val_accuracy: 0.5535\n",
      "Epoch 81/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.1006 - accuracy: 0.9663 - val_loss: 2.2171 - val_accuracy: 0.5602\n",
      "Epoch 82/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0925 - accuracy: 0.9680 - val_loss: 2.2457 - val_accuracy: 0.5555\n",
      "Epoch 83/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0993 - accuracy: 0.9671 - val_loss: 2.2089 - val_accuracy: 0.5557\n",
      "Epoch 84/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0985 - accuracy: 0.9673 - val_loss: 2.2299 - val_accuracy: 0.5555\n",
      "Epoch 85/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0937 - accuracy: 0.9675 - val_loss: 2.2116 - val_accuracy: 0.5586\n",
      "Epoch 86/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0891 - accuracy: 0.9699 - val_loss: 2.1969 - val_accuracy: 0.5574\n",
      "Epoch 87/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0941 - accuracy: 0.9673 - val_loss: 2.2146 - val_accuracy: 0.5535\n",
      "Epoch 88/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0931 - accuracy: 0.9676 - val_loss: 2.2287 - val_accuracy: 0.5543\n",
      "Epoch 89/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0936 - accuracy: 0.9676 - val_loss: 2.2261 - val_accuracy: 0.5524\n",
      "Epoch 90/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0925 - accuracy: 0.9686 - val_loss: 2.2398 - val_accuracy: 0.5577\n",
      "Epoch 91/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0925 - accuracy: 0.9695 - val_loss: 2.2353 - val_accuracy: 0.5510\n",
      "Epoch 92/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0975 - accuracy: 0.9682 - val_loss: 2.2337 - val_accuracy: 0.5515\n",
      "Epoch 93/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0936 - accuracy: 0.9693 - val_loss: 2.2200 - val_accuracy: 0.5572\n",
      "Epoch 94/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0980 - accuracy: 0.9652 - val_loss: 2.2020 - val_accuracy: 0.5614\n",
      "Epoch 95/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0933 - accuracy: 0.9667 - val_loss: 2.2186 - val_accuracy: 0.5619\n",
      "Epoch 96/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0925 - accuracy: 0.9666 - val_loss: 2.2088 - val_accuracy: 0.5569\n",
      "Epoch 97/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0861 - accuracy: 0.9704 - val_loss: 2.2290 - val_accuracy: 0.5588\n",
      "Epoch 98/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0887 - accuracy: 0.9684 - val_loss: 2.2269 - val_accuracy: 0.5552\n",
      "Epoch 99/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0901 - accuracy: 0.9683 - val_loss: 2.2293 - val_accuracy: 0.5563\n",
      "Epoch 100/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0892 - accuracy: 0.9676 - val_loss: 2.2062 - val_accuracy: 0.5670\n",
      "Epoch 101/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0888 - accuracy: 0.9676 - val_loss: 2.2108 - val_accuracy: 0.5538\n",
      "Epoch 102/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0876 - accuracy: 0.9682 - val_loss: 2.2190 - val_accuracy: 0.5566\n",
      "Epoch 103/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0844 - accuracy: 0.9677 - val_loss: 2.2523 - val_accuracy: 0.5560\n",
      "Epoch 104/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0874 - accuracy: 0.9704 - val_loss: 2.2262 - val_accuracy: 0.5572\n",
      "Epoch 105/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0860 - accuracy: 0.9691 - val_loss: 2.2786 - val_accuracy: 0.5515\n",
      "Epoch 106/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0856 - accuracy: 0.9686 - val_loss: 2.2145 - val_accuracy: 0.5591\n",
      "Epoch 107/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0921 - accuracy: 0.9676 - val_loss: 2.2193 - val_accuracy: 0.5594\n",
      "Epoch 108/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0851 - accuracy: 0.9699 - val_loss: 2.2465 - val_accuracy: 0.5532\n",
      "Epoch 109/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 2.2199 - val_accuracy: 0.5588\n",
      "Epoch 110/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0829 - accuracy: 0.9682 - val_loss: 2.2418 - val_accuracy: 0.5563\n",
      "Epoch 111/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0824 - accuracy: 0.9706 - val_loss: 2.2393 - val_accuracy: 0.5563\n",
      "Epoch 112/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0846 - accuracy: 0.9686 - val_loss: 2.2599 - val_accuracy: 0.5538\n",
      "Epoch 113/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0878 - accuracy: 0.9665 - val_loss: 2.2076 - val_accuracy: 0.5614\n",
      "Epoch 114/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0845 - accuracy: 0.9693 - val_loss: 2.2497 - val_accuracy: 0.5504\n",
      "Epoch 115/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0856 - accuracy: 0.9679 - val_loss: 2.2419 - val_accuracy: 0.5569\n",
      "Epoch 116/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0829 - accuracy: 0.9692 - val_loss: 2.2332 - val_accuracy: 0.5619\n",
      "Epoch 117/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0820 - accuracy: 0.9697 - val_loss: 2.2094 - val_accuracy: 0.5557\n",
      "Epoch 118/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0768 - accuracy: 0.9691 - val_loss: 2.2465 - val_accuracy: 0.5555\n",
      "Epoch 119/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0801 - accuracy: 0.9701 - val_loss: 2.2218 - val_accuracy: 0.5597\n",
      "Epoch 120/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0804 - accuracy: 0.9701 - val_loss: 2.2259 - val_accuracy: 0.5541\n",
      "Epoch 121/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0824 - accuracy: 0.9680 - val_loss: 2.2448 - val_accuracy: 0.5552\n",
      "Epoch 122/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0798 - accuracy: 0.9701 - val_loss: 2.2191 - val_accuracy: 0.5622\n",
      "Epoch 123/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0820 - accuracy: 0.9679 - val_loss: 2.2398 - val_accuracy: 0.5543\n",
      "Epoch 124/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0881 - accuracy: 0.9654 - val_loss: 2.1997 - val_accuracy: 0.5608\n",
      "Epoch 125/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0790 - accuracy: 0.9704 - val_loss: 2.2431 - val_accuracy: 0.5569\n",
      "Epoch 126/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0811 - accuracy: 0.9699 - val_loss: 2.2344 - val_accuracy: 0.5535\n",
      "Epoch 127/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0826 - accuracy: 0.9684 - val_loss: 2.2459 - val_accuracy: 0.5572\n",
      "Epoch 128/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0829 - accuracy: 0.9684 - val_loss: 2.2218 - val_accuracy: 0.5597\n",
      "Epoch 129/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0769 - accuracy: 0.9696 - val_loss: 2.2389 - val_accuracy: 0.5549\n",
      "Epoch 130/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0779 - accuracy: 0.9697 - val_loss: 2.2319 - val_accuracy: 0.5549\n",
      "Epoch 131/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0779 - accuracy: 0.9704 - val_loss: 2.2378 - val_accuracy: 0.5526\n",
      "Epoch 132/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0844 - accuracy: 0.9680 - val_loss: 2.2144 - val_accuracy: 0.5642\n",
      "Epoch 133/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0745 - accuracy: 0.9727 - val_loss: 2.2387 - val_accuracy: 0.5586\n",
      "Epoch 134/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0757 - accuracy: 0.9709 - val_loss: 2.2944 - val_accuracy: 0.5493\n",
      "Epoch 135/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0788 - accuracy: 0.9696 - val_loss: 2.2189 - val_accuracy: 0.5552\n",
      "Epoch 136/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0747 - accuracy: 0.9713 - val_loss: 2.2344 - val_accuracy: 0.5574\n",
      "Epoch 137/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0729 - accuracy: 0.9710 - val_loss: 2.2870 - val_accuracy: 0.5521\n",
      "Epoch 138/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0772 - accuracy: 0.9710 - val_loss: 2.2611 - val_accuracy: 0.5543\n",
      "Epoch 139/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0758 - accuracy: 0.9701 - val_loss: 2.2723 - val_accuracy: 0.5560\n",
      "Epoch 140/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0742 - accuracy: 0.9704 - val_loss: 2.2547 - val_accuracy: 0.5555\n",
      "Epoch 141/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0725 - accuracy: 0.9705 - val_loss: 2.2624 - val_accuracy: 0.5628\n",
      "Epoch 142/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0714 - accuracy: 0.9706 - val_loss: 2.2550 - val_accuracy: 0.5588\n",
      "Epoch 143/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0780 - accuracy: 0.9699 - val_loss: 2.2591 - val_accuracy: 0.5552\n",
      "Epoch 144/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0787 - accuracy: 0.9679 - val_loss: 2.2070 - val_accuracy: 0.5614\n",
      "Epoch 145/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0741 - accuracy: 0.9695 - val_loss: 2.2241 - val_accuracy: 0.5555\n",
      "Epoch 146/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0767 - accuracy: 0.9695 - val_loss: 2.2369 - val_accuracy: 0.5560\n",
      "Epoch 147/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0728 - accuracy: 0.9718 - val_loss: 2.2596 - val_accuracy: 0.5493\n",
      "Epoch 148/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0737 - accuracy: 0.9703 - val_loss: 2.2423 - val_accuracy: 0.5611\n",
      "Epoch 149/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0755 - accuracy: 0.9696 - val_loss: 2.2582 - val_accuracy: 0.5602\n",
      "Epoch 150/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0731 - accuracy: 0.9703 - val_loss: 2.2609 - val_accuracy: 0.5518\n",
      "Epoch 151/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0746 - accuracy: 0.9703 - val_loss: 2.2361 - val_accuracy: 0.5532\n",
      "Epoch 152/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0762 - accuracy: 0.9683 - val_loss: 2.2237 - val_accuracy: 0.5591\n",
      "Epoch 153/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.0744 - accuracy: 0.9683 - val_loss: 2.2291 - val_accuracy: 0.5586\n",
      "Epoch 154/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.0715 - accuracy: 0.9708 - val_loss: 2.2537 - val_accuracy: 0.5549\n",
      "Epoch 155/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0724 - accuracy: 0.9696 - val_loss: 2.2508 - val_accuracy: 0.5507\n",
      "Epoch 156/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0724 - accuracy: 0.9700 - val_loss: 2.2329 - val_accuracy: 0.5552\n",
      "Epoch 157/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0702 - accuracy: 0.9720 - val_loss: 2.2551 - val_accuracy: 0.5583\n",
      "Epoch 158/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0728 - accuracy: 0.9683 - val_loss: 2.2641 - val_accuracy: 0.5560\n",
      "Epoch 159/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0717 - accuracy: 0.9701 - val_loss: 2.2649 - val_accuracy: 0.5566\n",
      "Epoch 160/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0688 - accuracy: 0.9721 - val_loss: 2.2845 - val_accuracy: 0.5541\n",
      "Epoch 161/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0745 - accuracy: 0.9693 - val_loss: 2.2714 - val_accuracy: 0.5546\n",
      "Epoch 162/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0697 - accuracy: 0.9699 - val_loss: 2.2759 - val_accuracy: 0.5546\n",
      "Epoch 163/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0681 - accuracy: 0.9714 - val_loss: 2.2494 - val_accuracy: 0.5563\n",
      "Epoch 164/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0725 - accuracy: 0.9701 - val_loss: 2.2510 - val_accuracy: 0.5600\n",
      "Epoch 165/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0705 - accuracy: 0.9699 - val_loss: 2.2550 - val_accuracy: 0.5521\n",
      "Epoch 166/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0691 - accuracy: 0.9703 - val_loss: 2.2954 - val_accuracy: 0.5510\n",
      "Epoch 167/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0727 - accuracy: 0.9705 - val_loss: 2.2473 - val_accuracy: 0.5563\n",
      "Epoch 168/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0709 - accuracy: 0.9695 - val_loss: 2.2693 - val_accuracy: 0.5577\n",
      "Epoch 169/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0722 - accuracy: 0.9693 - val_loss: 2.2585 - val_accuracy: 0.5586\n",
      "Epoch 170/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.0716 - accuracy: 0.9693 - val_loss: 2.2751 - val_accuracy: 0.5555\n",
      "Epoch 171/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0717 - accuracy: 0.9684 - val_loss: 2.2693 - val_accuracy: 0.5541\n",
      "Epoch 172/1000\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.0685 - accuracy: 0.9718 - val_loss: 2.2489 - val_accuracy: 0.5569\n",
      "Epoch 173/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0738 - accuracy: 0.9695 - val_loss: 2.2576 - val_accuracy: 0.5594\n",
      "Epoch 174/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0673 - accuracy: 0.9721 - val_loss: 2.2577 - val_accuracy: 0.5580\n",
      "Epoch 175/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0675 - accuracy: 0.9722 - val_loss: 2.2614 - val_accuracy: 0.5572\n",
      "Epoch 176/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0662 - accuracy: 0.9706 - val_loss: 2.2579 - val_accuracy: 0.5631\n",
      "Epoch 177/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0715 - accuracy: 0.9689 - val_loss: 2.2633 - val_accuracy: 0.5572\n",
      "Epoch 178/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0701 - accuracy: 0.9699 - val_loss: 2.2688 - val_accuracy: 0.5591\n",
      "Epoch 179/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0656 - accuracy: 0.9720 - val_loss: 2.2716 - val_accuracy: 0.5549\n",
      "Epoch 180/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0684 - accuracy: 0.9712 - val_loss: 2.2694 - val_accuracy: 0.5504\n",
      "Epoch 181/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0687 - accuracy: 0.9713 - val_loss: 2.2791 - val_accuracy: 0.5549\n",
      "Epoch 182/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0665 - accuracy: 0.9710 - val_loss: 2.2791 - val_accuracy: 0.5543\n",
      "Epoch 183/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0691 - accuracy: 0.9704 - val_loss: 2.2548 - val_accuracy: 0.5577\n",
      "Epoch 184/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0672 - accuracy: 0.9718 - val_loss: 2.2353 - val_accuracy: 0.5639\n",
      "Epoch 185/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0670 - accuracy: 0.9693 - val_loss: 2.2691 - val_accuracy: 0.5535\n",
      "Epoch 186/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0657 - accuracy: 0.9727 - val_loss: 2.2754 - val_accuracy: 0.5512\n",
      "Epoch 187/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0702 - accuracy: 0.9700 - val_loss: 2.2600 - val_accuracy: 0.5625\n",
      "Epoch 188/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0616 - accuracy: 0.9729 - val_loss: 2.2676 - val_accuracy: 0.5574\n",
      "Epoch 189/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0663 - accuracy: 0.9704 - val_loss: 2.2775 - val_accuracy: 0.5566\n",
      "Epoch 190/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0626 - accuracy: 0.9727 - val_loss: 2.2831 - val_accuracy: 0.5560\n",
      "Epoch 191/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0639 - accuracy: 0.9710 - val_loss: 2.2784 - val_accuracy: 0.5574\n",
      "Epoch 192/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0695 - accuracy: 0.9704 - val_loss: 2.2887 - val_accuracy: 0.5577\n",
      "Epoch 193/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0666 - accuracy: 0.9697 - val_loss: 2.2837 - val_accuracy: 0.5566\n",
      "Epoch 194/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0638 - accuracy: 0.9729 - val_loss: 2.2974 - val_accuracy: 0.5580\n",
      "Epoch 195/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0656 - accuracy: 0.9710 - val_loss: 2.2729 - val_accuracy: 0.5588\n",
      "Epoch 196/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0695 - accuracy: 0.9693 - val_loss: 2.2774 - val_accuracy: 0.5498\n",
      "Epoch 197/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0674 - accuracy: 0.9708 - val_loss: 2.2712 - val_accuracy: 0.5600\n",
      "Epoch 198/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0632 - accuracy: 0.9712 - val_loss: 2.2863 - val_accuracy: 0.5532\n",
      "Epoch 199/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0668 - accuracy: 0.9708 - val_loss: 2.2763 - val_accuracy: 0.5526\n",
      "Epoch 200/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0667 - accuracy: 0.9718 - val_loss: 2.2836 - val_accuracy: 0.5541\n",
      "Epoch 201/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0669 - accuracy: 0.9722 - val_loss: 2.2772 - val_accuracy: 0.5580\n",
      "Epoch 202/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0651 - accuracy: 0.9725 - val_loss: 2.2821 - val_accuracy: 0.5586\n",
      "Epoch 203/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0644 - accuracy: 0.9705 - val_loss: 2.2423 - val_accuracy: 0.5560\n",
      "Epoch 204/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0661 - accuracy: 0.9712 - val_loss: 2.2562 - val_accuracy: 0.5572\n",
      "Epoch 205/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0632 - accuracy: 0.9714 - val_loss: 2.2592 - val_accuracy: 0.5560\n",
      "Epoch 206/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0590 - accuracy: 0.9740 - val_loss: 2.3003 - val_accuracy: 0.5602\n",
      "Epoch 207/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0657 - accuracy: 0.9716 - val_loss: 2.2585 - val_accuracy: 0.5557\n",
      "Epoch 208/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0621 - accuracy: 0.9710 - val_loss: 2.2749 - val_accuracy: 0.5622\n",
      "Epoch 209/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0624 - accuracy: 0.9716 - val_loss: 2.2693 - val_accuracy: 0.5591\n",
      "Epoch 210/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0628 - accuracy: 0.9708 - val_loss: 2.2771 - val_accuracy: 0.5572\n",
      "Epoch 211/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0617 - accuracy: 0.9727 - val_loss: 2.2934 - val_accuracy: 0.5591\n",
      "Epoch 212/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0650 - accuracy: 0.9717 - val_loss: 2.2838 - val_accuracy: 0.5580\n",
      "Epoch 213/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0639 - accuracy: 0.9712 - val_loss: 2.2627 - val_accuracy: 0.5577\n",
      "Epoch 214/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0617 - accuracy: 0.9701 - val_loss: 2.3146 - val_accuracy: 0.5580\n",
      "Epoch 215/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0625 - accuracy: 0.9730 - val_loss: 2.3040 - val_accuracy: 0.5566\n",
      "Epoch 216/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0629 - accuracy: 0.9717 - val_loss: 2.2937 - val_accuracy: 0.5580\n",
      "Epoch 217/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0647 - accuracy: 0.9689 - val_loss: 2.2692 - val_accuracy: 0.5625\n",
      "Epoch 218/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0643 - accuracy: 0.9721 - val_loss: 2.2528 - val_accuracy: 0.5583\n",
      "Epoch 219/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0582 - accuracy: 0.9731 - val_loss: 2.2562 - val_accuracy: 0.5563\n",
      "Epoch 220/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0630 - accuracy: 0.9725 - val_loss: 2.2586 - val_accuracy: 0.5608\n",
      "Epoch 221/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0614 - accuracy: 0.9706 - val_loss: 2.2737 - val_accuracy: 0.5538\n",
      "Epoch 222/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0636 - accuracy: 0.9721 - val_loss: 2.2752 - val_accuracy: 0.5580\n",
      "Epoch 223/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0628 - accuracy: 0.9701 - val_loss: 2.2603 - val_accuracy: 0.5580\n",
      "Epoch 224/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0626 - accuracy: 0.9704 - val_loss: 2.2811 - val_accuracy: 0.5580\n",
      "Epoch 225/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0635 - accuracy: 0.9716 - val_loss: 2.2673 - val_accuracy: 0.5541\n",
      "Epoch 226/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0600 - accuracy: 0.9713 - val_loss: 2.3238 - val_accuracy: 0.5518\n",
      "Epoch 227/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0621 - accuracy: 0.9705 - val_loss: 2.3075 - val_accuracy: 0.5591\n",
      "Epoch 228/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0608 - accuracy: 0.9709 - val_loss: 2.2922 - val_accuracy: 0.5572\n",
      "Epoch 229/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0616 - accuracy: 0.9712 - val_loss: 2.3072 - val_accuracy: 0.5569\n",
      "Epoch 230/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0626 - accuracy: 0.9723 - val_loss: 2.2727 - val_accuracy: 0.5597\n",
      "Epoch 231/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0600 - accuracy: 0.9721 - val_loss: 2.3032 - val_accuracy: 0.5557\n",
      "Epoch 232/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0643 - accuracy: 0.9709 - val_loss: 2.2662 - val_accuracy: 0.5594\n",
      "Epoch 233/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0645 - accuracy: 0.9693 - val_loss: 2.2515 - val_accuracy: 0.5566\n",
      "Epoch 234/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0581 - accuracy: 0.9718 - val_loss: 2.2761 - val_accuracy: 0.5586\n",
      "Epoch 235/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0617 - accuracy: 0.9721 - val_loss: 2.2856 - val_accuracy: 0.5572\n",
      "Epoch 236/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0612 - accuracy: 0.9731 - val_loss: 2.2747 - val_accuracy: 0.5600\n",
      "Epoch 237/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0611 - accuracy: 0.9720 - val_loss: 2.2801 - val_accuracy: 0.5636\n",
      "Epoch 238/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0630 - accuracy: 0.9703 - val_loss: 2.2710 - val_accuracy: 0.5597\n",
      "Epoch 239/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0584 - accuracy: 0.9730 - val_loss: 2.2876 - val_accuracy: 0.5572\n",
      "Epoch 240/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0601 - accuracy: 0.9721 - val_loss: 2.2966 - val_accuracy: 0.5546\n",
      "Epoch 241/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0596 - accuracy: 0.9727 - val_loss: 2.3069 - val_accuracy: 0.5495\n",
      "Epoch 242/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0591 - accuracy: 0.9716 - val_loss: 2.3203 - val_accuracy: 0.5538\n",
      "Epoch 243/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0611 - accuracy: 0.9706 - val_loss: 2.3036 - val_accuracy: 0.5549\n",
      "Epoch 244/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0633 - accuracy: 0.9703 - val_loss: 2.2867 - val_accuracy: 0.5614\n",
      "Epoch 245/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0578 - accuracy: 0.9731 - val_loss: 2.3144 - val_accuracy: 0.5529\n",
      "Epoch 246/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0628 - accuracy: 0.9706 - val_loss: 2.2800 - val_accuracy: 0.5577\n",
      "Epoch 247/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0585 - accuracy: 0.9720 - val_loss: 2.2906 - val_accuracy: 0.5597\n",
      "Epoch 248/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0595 - accuracy: 0.9706 - val_loss: 2.3019 - val_accuracy: 0.5580\n",
      "Epoch 249/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0572 - accuracy: 0.9735 - val_loss: 2.2986 - val_accuracy: 0.5586\n",
      "Epoch 250/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0629 - accuracy: 0.9708 - val_loss: 2.2959 - val_accuracy: 0.5611\n",
      "Epoch 251/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0607 - accuracy: 0.9693 - val_loss: 2.3138 - val_accuracy: 0.5543\n",
      "Epoch 252/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0615 - accuracy: 0.9705 - val_loss: 2.3141 - val_accuracy: 0.5515\n",
      "Epoch 253/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0611 - accuracy: 0.9704 - val_loss: 2.2828 - val_accuracy: 0.5591\n",
      "Epoch 254/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0601 - accuracy: 0.9721 - val_loss: 2.3099 - val_accuracy: 0.5532\n",
      "Epoch 255/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0580 - accuracy: 0.9730 - val_loss: 2.3035 - val_accuracy: 0.5572\n",
      "Epoch 256/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0611 - accuracy: 0.9704 - val_loss: 2.3049 - val_accuracy: 0.5636\n",
      "Epoch 257/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0594 - accuracy: 0.9723 - val_loss: 2.3151 - val_accuracy: 0.5586\n",
      "Epoch 258/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0593 - accuracy: 0.9718 - val_loss: 2.3034 - val_accuracy: 0.5602\n",
      "Epoch 259/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0608 - accuracy: 0.9718 - val_loss: 2.3221 - val_accuracy: 0.5563\n",
      "Epoch 260/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0564 - accuracy: 0.9712 - val_loss: 2.3140 - val_accuracy: 0.5566\n",
      "Epoch 261/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0599 - accuracy: 0.9703 - val_loss: 2.3300 - val_accuracy: 0.5608\n",
      "Epoch 262/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0618 - accuracy: 0.9713 - val_loss: 2.3113 - val_accuracy: 0.5577\n",
      "Epoch 263/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0580 - accuracy: 0.9717 - val_loss: 2.3236 - val_accuracy: 0.5572\n",
      "Epoch 264/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0582 - accuracy: 0.9727 - val_loss: 2.3128 - val_accuracy: 0.5543\n",
      "Epoch 265/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0573 - accuracy: 0.9708 - val_loss: 2.3284 - val_accuracy: 0.5591\n",
      "Epoch 266/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0577 - accuracy: 0.9718 - val_loss: 2.3061 - val_accuracy: 0.5555\n",
      "Epoch 267/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0592 - accuracy: 0.9712 - val_loss: 2.3087 - val_accuracy: 0.5577\n",
      "Epoch 268/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0618 - accuracy: 0.9693 - val_loss: 2.2833 - val_accuracy: 0.5583\n",
      "Epoch 269/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0589 - accuracy: 0.9700 - val_loss: 2.3082 - val_accuracy: 0.5591\n",
      "Epoch 270/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0586 - accuracy: 0.9722 - val_loss: 2.3156 - val_accuracy: 0.5529\n",
      "Epoch 271/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0571 - accuracy: 0.9738 - val_loss: 2.3266 - val_accuracy: 0.5535\n",
      "Epoch 272/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0576 - accuracy: 0.9723 - val_loss: 2.3234 - val_accuracy: 0.5580\n",
      "Epoch 273/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0572 - accuracy: 0.9704 - val_loss: 2.3094 - val_accuracy: 0.5572\n",
      "Epoch 274/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0570 - accuracy: 0.9726 - val_loss: 2.3507 - val_accuracy: 0.5507\n",
      "Epoch 275/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0588 - accuracy: 0.9718 - val_loss: 2.3347 - val_accuracy: 0.5501\n",
      "Epoch 276/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0569 - accuracy: 0.9721 - val_loss: 2.3195 - val_accuracy: 0.5563\n",
      "Epoch 277/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0562 - accuracy: 0.9725 - val_loss: 2.3194 - val_accuracy: 0.5543\n",
      "Epoch 278/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0579 - accuracy: 0.9710 - val_loss: 2.3067 - val_accuracy: 0.5546\n",
      "Epoch 279/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0567 - accuracy: 0.9739 - val_loss: 2.3041 - val_accuracy: 0.5622\n",
      "Epoch 280/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0569 - accuracy: 0.9721 - val_loss: 2.3216 - val_accuracy: 0.5560\n",
      "Epoch 281/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0569 - accuracy: 0.9716 - val_loss: 2.3517 - val_accuracy: 0.5515\n",
      "Epoch 282/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0568 - accuracy: 0.9725 - val_loss: 2.3344 - val_accuracy: 0.5541\n",
      "Epoch 283/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0565 - accuracy: 0.9717 - val_loss: 2.3380 - val_accuracy: 0.5580\n",
      "Epoch 284/1000\n",
      "240/240 [==============================] - 69s 289ms/step - loss: 0.0577 - accuracy: 0.9710 - val_loss: 2.3414 - val_accuracy: 0.5493\n",
      "Epoch 285/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0558 - accuracy: 0.9713 - val_loss: 2.3472 - val_accuracy: 0.5538\n",
      "Epoch 286/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0578 - accuracy: 0.9723 - val_loss: 2.3385 - val_accuracy: 0.5510\n",
      "Epoch 287/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0591 - accuracy: 0.9700 - val_loss: 2.3392 - val_accuracy: 0.5569\n",
      "Epoch 288/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0583 - accuracy: 0.9703 - val_loss: 2.3075 - val_accuracy: 0.5535\n",
      "Epoch 289/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0585 - accuracy: 0.9712 - val_loss: 2.3035 - val_accuracy: 0.5566\n",
      "Epoch 290/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0542 - accuracy: 0.9720 - val_loss: 2.3266 - val_accuracy: 0.5543\n",
      "Epoch 291/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0555 - accuracy: 0.9714 - val_loss: 2.3328 - val_accuracy: 0.5555\n",
      "Epoch 292/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0551 - accuracy: 0.9723 - val_loss: 2.3333 - val_accuracy: 0.5631\n",
      "Epoch 293/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0568 - accuracy: 0.9734 - val_loss: 2.3285 - val_accuracy: 0.5594\n",
      "Epoch 294/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0571 - accuracy: 0.9717 - val_loss: 2.3171 - val_accuracy: 0.5557\n",
      "Epoch 295/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0558 - accuracy: 0.9730 - val_loss: 2.3238 - val_accuracy: 0.5586\n",
      "Epoch 296/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0561 - accuracy: 0.9712 - val_loss: 2.3193 - val_accuracy: 0.5588\n",
      "Epoch 297/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0575 - accuracy: 0.9726 - val_loss: 2.3177 - val_accuracy: 0.5586\n",
      "Epoch 298/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0544 - accuracy: 0.9736 - val_loss: 2.3397 - val_accuracy: 0.5614\n",
      "Epoch 299/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0567 - accuracy: 0.9720 - val_loss: 2.3146 - val_accuracy: 0.5597\n",
      "Epoch 300/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0553 - accuracy: 0.9718 - val_loss: 2.3454 - val_accuracy: 0.5611\n",
      "Epoch 301/1000\n",
      "240/240 [==============================] - 68s 283ms/step - loss: 0.0560 - accuracy: 0.9721 - val_loss: 2.3250 - val_accuracy: 0.5574\n",
      "Epoch 302/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0573 - accuracy: 0.9704 - val_loss: 2.3347 - val_accuracy: 0.5569\n",
      "Epoch 303/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0540 - accuracy: 0.9736 - val_loss: 2.3291 - val_accuracy: 0.5560\n",
      "Epoch 304/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0569 - accuracy: 0.9710 - val_loss: 2.3272 - val_accuracy: 0.5583\n",
      "Epoch 305/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0578 - accuracy: 0.9717 - val_loss: 2.3196 - val_accuracy: 0.5524\n",
      "Epoch 306/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0558 - accuracy: 0.9718 - val_loss: 2.3242 - val_accuracy: 0.5597\n",
      "Epoch 307/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0546 - accuracy: 0.9725 - val_loss: 2.3123 - val_accuracy: 0.5546\n",
      "Epoch 308/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0536 - accuracy: 0.9730 - val_loss: 2.3246 - val_accuracy: 0.5583\n",
      "Epoch 309/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0555 - accuracy: 0.9712 - val_loss: 2.3438 - val_accuracy: 0.5586\n",
      "Epoch 310/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0540 - accuracy: 0.9721 - val_loss: 2.3319 - val_accuracy: 0.5543\n",
      "Epoch 311/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0558 - accuracy: 0.9725 - val_loss: 2.3431 - val_accuracy: 0.5515\n",
      "Epoch 312/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0540 - accuracy: 0.9725 - val_loss: 2.3417 - val_accuracy: 0.5541\n",
      "Epoch 313/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0536 - accuracy: 0.9727 - val_loss: 2.3349 - val_accuracy: 0.5574\n",
      "Epoch 314/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0565 - accuracy: 0.9706 - val_loss: 2.3366 - val_accuracy: 0.5563\n",
      "Epoch 315/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0540 - accuracy: 0.9730 - val_loss: 2.3417 - val_accuracy: 0.5543\n",
      "Epoch 316/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0542 - accuracy: 0.9733 - val_loss: 2.3414 - val_accuracy: 0.5552\n",
      "Epoch 317/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0581 - accuracy: 0.9716 - val_loss: 2.3130 - val_accuracy: 0.5608\n",
      "Epoch 318/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0538 - accuracy: 0.9726 - val_loss: 2.3463 - val_accuracy: 0.5543\n",
      "Epoch 319/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0578 - accuracy: 0.9703 - val_loss: 2.3494 - val_accuracy: 0.5546\n",
      "Epoch 320/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0546 - accuracy: 0.9731 - val_loss: 2.3596 - val_accuracy: 0.5543\n",
      "Epoch 321/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0527 - accuracy: 0.9748 - val_loss: 2.3235 - val_accuracy: 0.5591\n",
      "Epoch 322/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0520 - accuracy: 0.9744 - val_loss: 2.3643 - val_accuracy: 0.5535\n",
      "Epoch 323/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0556 - accuracy: 0.9722 - val_loss: 2.3503 - val_accuracy: 0.5555\n",
      "Epoch 324/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0564 - accuracy: 0.9705 - val_loss: 2.3293 - val_accuracy: 0.5549\n",
      "Epoch 325/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0531 - accuracy: 0.9729 - val_loss: 2.3407 - val_accuracy: 0.5524\n",
      "Epoch 326/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0545 - accuracy: 0.9733 - val_loss: 2.3339 - val_accuracy: 0.5591\n",
      "Epoch 327/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0559 - accuracy: 0.9723 - val_loss: 2.3281 - val_accuracy: 0.5555\n",
      "Epoch 328/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0547 - accuracy: 0.9734 - val_loss: 2.3310 - val_accuracy: 0.5577\n",
      "Epoch 329/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0535 - accuracy: 0.9730 - val_loss: 2.3459 - val_accuracy: 0.5552\n",
      "Epoch 330/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0542 - accuracy: 0.9716 - val_loss: 2.3244 - val_accuracy: 0.5583\n",
      "Epoch 331/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0542 - accuracy: 0.9726 - val_loss: 2.3451 - val_accuracy: 0.5526\n",
      "Epoch 332/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0535 - accuracy: 0.9730 - val_loss: 2.3535 - val_accuracy: 0.5535\n",
      "Epoch 333/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0541 - accuracy: 0.9723 - val_loss: 2.3525 - val_accuracy: 0.5510\n",
      "Epoch 334/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0560 - accuracy: 0.9717 - val_loss: 2.3649 - val_accuracy: 0.5518\n",
      "Epoch 335/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0530 - accuracy: 0.9721 - val_loss: 2.3295 - val_accuracy: 0.5566\n",
      "Epoch 336/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0541 - accuracy: 0.9721 - val_loss: 2.3375 - val_accuracy: 0.5507\n",
      "Epoch 337/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0545 - accuracy: 0.9731 - val_loss: 2.3659 - val_accuracy: 0.5493\n",
      "Epoch 338/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0553 - accuracy: 0.9716 - val_loss: 2.3349 - val_accuracy: 0.5580\n",
      "Epoch 339/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0539 - accuracy: 0.9713 - val_loss: 2.3633 - val_accuracy: 0.5563\n",
      "Epoch 340/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0524 - accuracy: 0.9742 - val_loss: 2.3622 - val_accuracy: 0.5510\n",
      "Epoch 341/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0561 - accuracy: 0.9718 - val_loss: 2.3137 - val_accuracy: 0.5594\n",
      "Epoch 342/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0499 - accuracy: 0.9744 - val_loss: 2.3373 - val_accuracy: 0.5586\n",
      "Epoch 343/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0525 - accuracy: 0.9726 - val_loss: 2.3447 - val_accuracy: 0.5532\n",
      "Epoch 344/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0519 - accuracy: 0.9729 - val_loss: 2.3559 - val_accuracy: 0.5557\n",
      "Epoch 345/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0518 - accuracy: 0.9729 - val_loss: 2.3599 - val_accuracy: 0.5555\n",
      "Epoch 346/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0562 - accuracy: 0.9714 - val_loss: 2.3387 - val_accuracy: 0.5560\n",
      "Epoch 347/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0540 - accuracy: 0.9720 - val_loss: 2.3356 - val_accuracy: 0.5543\n",
      "Epoch 348/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0530 - accuracy: 0.9714 - val_loss: 2.3589 - val_accuracy: 0.5501\n",
      "Epoch 349/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0515 - accuracy: 0.9721 - val_loss: 2.3724 - val_accuracy: 0.5557\n",
      "Epoch 350/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0541 - accuracy: 0.9734 - val_loss: 2.3673 - val_accuracy: 0.5538\n",
      "Epoch 351/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0533 - accuracy: 0.9730 - val_loss: 2.3467 - val_accuracy: 0.5566\n",
      "Epoch 352/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0511 - accuracy: 0.9740 - val_loss: 2.3361 - val_accuracy: 0.5583\n",
      "Epoch 353/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0544 - accuracy: 0.9722 - val_loss: 2.3249 - val_accuracy: 0.5600\n",
      "Epoch 354/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0514 - accuracy: 0.9731 - val_loss: 2.3833 - val_accuracy: 0.5541\n",
      "Epoch 355/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0534 - accuracy: 0.9750 - val_loss: 2.3682 - val_accuracy: 0.5619\n",
      "Epoch 356/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0514 - accuracy: 0.9735 - val_loss: 2.3600 - val_accuracy: 0.5572\n",
      "Epoch 357/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0543 - accuracy: 0.9725 - val_loss: 2.3499 - val_accuracy: 0.5560\n",
      "Epoch 358/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0512 - accuracy: 0.9731 - val_loss: 2.3580 - val_accuracy: 0.5574\n",
      "Epoch 359/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0564 - accuracy: 0.9717 - val_loss: 2.3516 - val_accuracy: 0.5529\n",
      "Epoch 360/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0518 - accuracy: 0.9721 - val_loss: 2.3532 - val_accuracy: 0.5605\n",
      "Epoch 361/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0521 - accuracy: 0.9727 - val_loss: 2.3501 - val_accuracy: 0.5557\n",
      "Epoch 362/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0530 - accuracy: 0.9721 - val_loss: 2.3664 - val_accuracy: 0.5586\n",
      "Epoch 363/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0525 - accuracy: 0.9722 - val_loss: 2.3401 - val_accuracy: 0.5555\n",
      "Epoch 364/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0518 - accuracy: 0.9738 - val_loss: 2.3513 - val_accuracy: 0.5521\n",
      "Epoch 365/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0531 - accuracy: 0.9714 - val_loss: 2.3587 - val_accuracy: 0.5532\n",
      "Epoch 366/1000\n",
      "240/240 [==============================] - 70s 291ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 2.3655 - val_accuracy: 0.5572\n",
      "Epoch 367/1000\n",
      "240/240 [==============================] - 70s 293ms/step - loss: 0.0520 - accuracy: 0.9740 - val_loss: 2.3223 - val_accuracy: 0.5563\n",
      "Epoch 368/1000\n",
      "240/240 [==============================] - 70s 293ms/step - loss: 0.0543 - accuracy: 0.9713 - val_loss: 2.3275 - val_accuracy: 0.5594\n",
      "Epoch 369/1000\n",
      "240/240 [==============================] - 70s 293ms/step - loss: 0.0537 - accuracy: 0.9720 - val_loss: 2.3332 - val_accuracy: 0.5555\n",
      "Epoch 370/1000\n",
      "240/240 [==============================] - 70s 294ms/step - loss: 0.0514 - accuracy: 0.9736 - val_loss: 2.3499 - val_accuracy: 0.5518\n",
      "Epoch 371/1000\n",
      "240/240 [==============================] - 71s 294ms/step - loss: 0.0513 - accuracy: 0.9731 - val_loss: 2.3885 - val_accuracy: 0.5493\n",
      "Epoch 372/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0521 - accuracy: 0.9725 - val_loss: 2.3929 - val_accuracy: 0.5557\n",
      "Epoch 373/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0518 - accuracy: 0.9717 - val_loss: 2.3635 - val_accuracy: 0.5521\n",
      "Epoch 374/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0524 - accuracy: 0.9733 - val_loss: 2.3604 - val_accuracy: 0.5591\n",
      "Epoch 375/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0522 - accuracy: 0.9738 - val_loss: 2.3598 - val_accuracy: 0.5510\n",
      "Epoch 376/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0511 - accuracy: 0.9731 - val_loss: 2.3573 - val_accuracy: 0.5563\n",
      "Epoch 377/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0530 - accuracy: 0.9706 - val_loss: 2.3652 - val_accuracy: 0.5577\n",
      "Epoch 378/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0510 - accuracy: 0.9723 - val_loss: 2.3854 - val_accuracy: 0.5521\n",
      "Epoch 379/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0524 - accuracy: 0.9720 - val_loss: 2.3655 - val_accuracy: 0.5543\n",
      "Epoch 380/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0521 - accuracy: 0.9718 - val_loss: 2.3570 - val_accuracy: 0.5524\n",
      "Epoch 381/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0503 - accuracy: 0.9736 - val_loss: 2.3529 - val_accuracy: 0.5560\n",
      "Epoch 382/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0531 - accuracy: 0.9701 - val_loss: 2.3530 - val_accuracy: 0.5560\n",
      "Epoch 383/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0505 - accuracy: 0.9734 - val_loss: 2.3688 - val_accuracy: 0.5560\n",
      "Epoch 384/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0494 - accuracy: 0.9743 - val_loss: 2.3573 - val_accuracy: 0.5557\n",
      "Epoch 385/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0519 - accuracy: 0.9714 - val_loss: 2.3645 - val_accuracy: 0.5512\n",
      "Epoch 386/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0511 - accuracy: 0.9733 - val_loss: 2.3708 - val_accuracy: 0.5560\n",
      "Epoch 387/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0517 - accuracy: 0.9727 - val_loss: 2.3691 - val_accuracy: 0.5538\n",
      "Epoch 388/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0508 - accuracy: 0.9730 - val_loss: 2.3838 - val_accuracy: 0.5560\n",
      "Epoch 389/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0496 - accuracy: 0.9726 - val_loss: 2.3859 - val_accuracy: 0.5580\n",
      "Epoch 390/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0514 - accuracy: 0.9722 - val_loss: 2.3846 - val_accuracy: 0.5541\n",
      "Epoch 391/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0513 - accuracy: 0.9723 - val_loss: 2.3654 - val_accuracy: 0.5524\n",
      "Epoch 392/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0544 - accuracy: 0.9720 - val_loss: 2.3526 - val_accuracy: 0.5501\n",
      "Epoch 393/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0517 - accuracy: 0.9731 - val_loss: 2.3741 - val_accuracy: 0.5535\n",
      "Epoch 394/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0506 - accuracy: 0.9740 - val_loss: 2.3739 - val_accuracy: 0.5580\n",
      "Epoch 395/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0492 - accuracy: 0.9735 - val_loss: 2.3780 - val_accuracy: 0.5507\n",
      "Epoch 396/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0525 - accuracy: 0.9727 - val_loss: 2.3723 - val_accuracy: 0.5557\n",
      "Epoch 397/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0513 - accuracy: 0.9723 - val_loss: 2.3924 - val_accuracy: 0.5560\n",
      "Epoch 398/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0493 - accuracy: 0.9759 - val_loss: 2.4029 - val_accuracy: 0.5510\n",
      "Epoch 399/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0521 - accuracy: 0.9716 - val_loss: 2.4009 - val_accuracy: 0.5563\n",
      "Epoch 400/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0523 - accuracy: 0.9733 - val_loss: 2.3922 - val_accuracy: 0.5487\n",
      "Epoch 401/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0484 - accuracy: 0.9736 - val_loss: 2.4169 - val_accuracy: 0.5512\n",
      "Epoch 402/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0496 - accuracy: 0.9739 - val_loss: 2.4080 - val_accuracy: 0.5541\n",
      "Epoch 403/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0506 - accuracy: 0.9713 - val_loss: 2.4207 - val_accuracy: 0.5532\n",
      "Epoch 404/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0515 - accuracy: 0.9712 - val_loss: 2.3829 - val_accuracy: 0.5543\n",
      "Epoch 405/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0503 - accuracy: 0.9718 - val_loss: 2.3954 - val_accuracy: 0.5526\n",
      "Epoch 406/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0511 - accuracy: 0.9735 - val_loss: 2.3940 - val_accuracy: 0.5529\n",
      "Epoch 407/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0519 - accuracy: 0.9709 - val_loss: 2.3937 - val_accuracy: 0.5479\n",
      "Epoch 408/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0507 - accuracy: 0.9727 - val_loss: 2.3683 - val_accuracy: 0.5484\n",
      "Epoch 409/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0509 - accuracy: 0.9718 - val_loss: 2.3902 - val_accuracy: 0.5512\n",
      "Epoch 410/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0510 - accuracy: 0.9738 - val_loss: 2.3852 - val_accuracy: 0.5535\n",
      "Epoch 411/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0492 - accuracy: 0.9729 - val_loss: 2.3885 - val_accuracy: 0.5507\n",
      "Epoch 412/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0516 - accuracy: 0.9731 - val_loss: 2.3491 - val_accuracy: 0.5526\n",
      "Epoch 413/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0493 - accuracy: 0.9734 - val_loss: 2.4032 - val_accuracy: 0.5541\n",
      "Epoch 414/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0515 - accuracy: 0.9713 - val_loss: 2.3884 - val_accuracy: 0.5507\n",
      "Epoch 415/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0504 - accuracy: 0.9734 - val_loss: 2.3877 - val_accuracy: 0.5515\n",
      "Epoch 416/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0493 - accuracy: 0.9736 - val_loss: 2.3975 - val_accuracy: 0.5538\n",
      "Epoch 417/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0499 - accuracy: 0.9736 - val_loss: 2.3883 - val_accuracy: 0.5515\n",
      "Epoch 418/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0478 - accuracy: 0.9739 - val_loss: 2.4037 - val_accuracy: 0.5532\n",
      "Epoch 419/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0503 - accuracy: 0.9719 - val_loss: 2.3914 - val_accuracy: 0.5518\n",
      "Epoch 420/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0493 - accuracy: 0.9731 - val_loss: 2.4035 - val_accuracy: 0.5504\n",
      "Epoch 421/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0506 - accuracy: 0.9746 - val_loss: 2.3955 - val_accuracy: 0.5518\n",
      "Epoch 422/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0531 - accuracy: 0.9712 - val_loss: 2.3873 - val_accuracy: 0.5541\n",
      "Epoch 423/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0499 - accuracy: 0.9727 - val_loss: 2.3838 - val_accuracy: 0.5541\n",
      "Epoch 424/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0499 - accuracy: 0.9722 - val_loss: 2.4059 - val_accuracy: 0.5504\n",
      "Epoch 425/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0470 - accuracy: 0.9727 - val_loss: 2.3971 - val_accuracy: 0.5560\n",
      "Epoch 426/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0477 - accuracy: 0.9746 - val_loss: 2.3926 - val_accuracy: 0.5546\n",
      "Epoch 427/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0486 - accuracy: 0.9723 - val_loss: 2.3968 - val_accuracy: 0.5535\n",
      "Epoch 428/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0517 - accuracy: 0.9734 - val_loss: 2.4068 - val_accuracy: 0.5541\n",
      "Epoch 429/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0519 - accuracy: 0.9743 - val_loss: 2.4059 - val_accuracy: 0.5541\n",
      "Epoch 430/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0492 - accuracy: 0.9744 - val_loss: 2.4071 - val_accuracy: 0.5524\n",
      "Epoch 431/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0500 - accuracy: 0.9733 - val_loss: 2.3892 - val_accuracy: 0.5507\n",
      "Epoch 432/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0536 - accuracy: 0.9717 - val_loss: 2.3784 - val_accuracy: 0.5555\n",
      "Epoch 433/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0477 - accuracy: 0.9735 - val_loss: 2.4001 - val_accuracy: 0.5526\n",
      "Epoch 434/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0475 - accuracy: 0.9735 - val_loss: 2.3952 - val_accuracy: 0.5563\n",
      "Epoch 435/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0485 - accuracy: 0.9739 - val_loss: 2.4047 - val_accuracy: 0.5510\n",
      "Epoch 436/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0490 - accuracy: 0.9747 - val_loss: 2.4044 - val_accuracy: 0.5526\n",
      "Epoch 437/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0482 - accuracy: 0.9725 - val_loss: 2.4059 - val_accuracy: 0.5515\n",
      "Epoch 438/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0523 - accuracy: 0.9727 - val_loss: 2.3767 - val_accuracy: 0.5538\n",
      "Epoch 439/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0499 - accuracy: 0.9729 - val_loss: 2.3757 - val_accuracy: 0.5605\n",
      "Epoch 440/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0492 - accuracy: 0.9734 - val_loss: 2.3986 - val_accuracy: 0.5566\n",
      "Epoch 441/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0480 - accuracy: 0.9752 - val_loss: 2.4010 - val_accuracy: 0.5552\n",
      "Epoch 442/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0491 - accuracy: 0.9731 - val_loss: 2.3882 - val_accuracy: 0.5555\n",
      "Epoch 443/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0505 - accuracy: 0.9720 - val_loss: 2.3805 - val_accuracy: 0.5535\n",
      "Epoch 444/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0467 - accuracy: 0.9727 - val_loss: 2.4011 - val_accuracy: 0.5515\n",
      "Epoch 445/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0516 - accuracy: 0.9720 - val_loss: 2.3879 - val_accuracy: 0.5507\n",
      "Epoch 446/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0509 - accuracy: 0.9733 - val_loss: 2.3851 - val_accuracy: 0.5495\n",
      "Epoch 447/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0469 - accuracy: 0.9743 - val_loss: 2.4067 - val_accuracy: 0.5501\n",
      "Epoch 448/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0517 - accuracy: 0.9717 - val_loss: 2.4015 - val_accuracy: 0.5512\n",
      "Epoch 449/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0494 - accuracy: 0.9736 - val_loss: 2.4062 - val_accuracy: 0.5487\n",
      "Epoch 450/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0499 - accuracy: 0.9735 - val_loss: 2.4059 - val_accuracy: 0.5498\n",
      "Epoch 451/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0480 - accuracy: 0.9727 - val_loss: 2.4122 - val_accuracy: 0.5526\n",
      "Epoch 452/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0488 - accuracy: 0.9729 - val_loss: 2.4206 - val_accuracy: 0.5510\n",
      "Epoch 453/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0509 - accuracy: 0.9714 - val_loss: 2.4078 - val_accuracy: 0.5487\n",
      "Epoch 454/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0478 - accuracy: 0.9743 - val_loss: 2.4152 - val_accuracy: 0.5546\n",
      "Epoch 455/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0480 - accuracy: 0.9738 - val_loss: 2.4168 - val_accuracy: 0.5546\n",
      "Epoch 456/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0484 - accuracy: 0.9744 - val_loss: 2.4363 - val_accuracy: 0.5507\n",
      "Epoch 457/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0514 - accuracy: 0.9723 - val_loss: 2.3971 - val_accuracy: 0.5588\n",
      "Epoch 458/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0503 - accuracy: 0.9713 - val_loss: 2.3953 - val_accuracy: 0.5487\n",
      "Epoch 459/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0470 - accuracy: 0.9735 - val_loss: 2.4194 - val_accuracy: 0.5501\n",
      "Epoch 460/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0502 - accuracy: 0.9717 - val_loss: 2.3840 - val_accuracy: 0.5493\n",
      "Epoch 461/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0487 - accuracy: 0.9743 - val_loss: 2.4005 - val_accuracy: 0.5543\n",
      "Epoch 462/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0486 - accuracy: 0.9722 - val_loss: 2.4119 - val_accuracy: 0.5515\n",
      "Epoch 463/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0484 - accuracy: 0.9714 - val_loss: 2.4040 - val_accuracy: 0.5493\n",
      "Epoch 464/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0488 - accuracy: 0.9735 - val_loss: 2.3993 - val_accuracy: 0.5515\n",
      "Epoch 465/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0484 - accuracy: 0.9736 - val_loss: 2.3878 - val_accuracy: 0.5563\n",
      "Epoch 466/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0498 - accuracy: 0.9726 - val_loss: 2.3986 - val_accuracy: 0.5546\n",
      "Epoch 467/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0469 - accuracy: 0.9743 - val_loss: 2.4153 - val_accuracy: 0.5484\n",
      "Epoch 468/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0470 - accuracy: 0.9730 - val_loss: 2.4246 - val_accuracy: 0.5507\n",
      "Epoch 469/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0488 - accuracy: 0.9731 - val_loss: 2.4293 - val_accuracy: 0.5501\n",
      "Epoch 470/1000\n",
      "240/240 [==============================] - 70s 291ms/step - loss: 0.0491 - accuracy: 0.9730 - val_loss: 2.4250 - val_accuracy: 0.5591\n",
      "Epoch 471/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0485 - accuracy: 0.9716 - val_loss: 2.4259 - val_accuracy: 0.5535\n",
      "Epoch 472/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0475 - accuracy: 0.9744 - val_loss: 2.4117 - val_accuracy: 0.5521\n",
      "Epoch 473/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0506 - accuracy: 0.9716 - val_loss: 2.4101 - val_accuracy: 0.5510\n",
      "Epoch 474/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0484 - accuracy: 0.9733 - val_loss: 2.4002 - val_accuracy: 0.5580\n",
      "Epoch 475/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0459 - accuracy: 0.9748 - val_loss: 2.4228 - val_accuracy: 0.5577\n",
      "Epoch 476/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0463 - accuracy: 0.9747 - val_loss: 2.4279 - val_accuracy: 0.5577\n",
      "Epoch 477/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0481 - accuracy: 0.9743 - val_loss: 2.4116 - val_accuracy: 0.5507\n",
      "Epoch 478/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0470 - accuracy: 0.9736 - val_loss: 2.4431 - val_accuracy: 0.5504\n",
      "Epoch 479/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0475 - accuracy: 0.9730 - val_loss: 2.4529 - val_accuracy: 0.5569\n",
      "Epoch 480/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0477 - accuracy: 0.9730 - val_loss: 2.4443 - val_accuracy: 0.5538\n",
      "Epoch 481/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0468 - accuracy: 0.9748 - val_loss: 2.4219 - val_accuracy: 0.5512\n",
      "Epoch 482/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0464 - accuracy: 0.9731 - val_loss: 2.4275 - val_accuracy: 0.5521\n",
      "Epoch 483/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0485 - accuracy: 0.9720 - val_loss: 2.4137 - val_accuracy: 0.5526\n",
      "Epoch 484/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0461 - accuracy: 0.9746 - val_loss: 2.4222 - val_accuracy: 0.5552\n",
      "Epoch 485/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0463 - accuracy: 0.9735 - val_loss: 2.4172 - val_accuracy: 0.5563\n",
      "Epoch 486/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0505 - accuracy: 0.9716 - val_loss: 2.4237 - val_accuracy: 0.5549\n",
      "Epoch 487/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0473 - accuracy: 0.9746 - val_loss: 2.4149 - val_accuracy: 0.5552\n",
      "Epoch 488/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0487 - accuracy: 0.9738 - val_loss: 2.4161 - val_accuracy: 0.5557\n",
      "Epoch 489/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0476 - accuracy: 0.9734 - val_loss: 2.4317 - val_accuracy: 0.5512\n",
      "Epoch 490/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0492 - accuracy: 0.9722 - val_loss: 2.4219 - val_accuracy: 0.5543\n",
      "Epoch 491/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0484 - accuracy: 0.9727 - val_loss: 2.4040 - val_accuracy: 0.5541\n",
      "Epoch 492/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0484 - accuracy: 0.9742 - val_loss: 2.3932 - val_accuracy: 0.5543\n",
      "Epoch 493/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0473 - accuracy: 0.9731 - val_loss: 2.4027 - val_accuracy: 0.5481\n",
      "Epoch 494/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0469 - accuracy: 0.9748 - val_loss: 2.4065 - val_accuracy: 0.5552\n",
      "Epoch 495/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0476 - accuracy: 0.9742 - val_loss: 2.4257 - val_accuracy: 0.5504\n",
      "Epoch 496/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0488 - accuracy: 0.9723 - val_loss: 2.4191 - val_accuracy: 0.5504\n",
      "Epoch 497/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0476 - accuracy: 0.9743 - val_loss: 2.4081 - val_accuracy: 0.5557\n",
      "Epoch 498/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0467 - accuracy: 0.9751 - val_loss: 2.4259 - val_accuracy: 0.5541\n",
      "Epoch 499/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0473 - accuracy: 0.9721 - val_loss: 2.4230 - val_accuracy: 0.5521\n",
      "Epoch 500/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0487 - accuracy: 0.9726 - val_loss: 2.4195 - val_accuracy: 0.5490\n",
      "Epoch 501/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0472 - accuracy: 0.9730 - val_loss: 2.4055 - val_accuracy: 0.5543\n",
      "Epoch 502/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0458 - accuracy: 0.9752 - val_loss: 2.4306 - val_accuracy: 0.5515\n",
      "Epoch 503/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0456 - accuracy: 0.9734 - val_loss: 2.4536 - val_accuracy: 0.5498\n",
      "Epoch 504/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0467 - accuracy: 0.9738 - val_loss: 2.4495 - val_accuracy: 0.5465\n",
      "Epoch 505/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0480 - accuracy: 0.9731 - val_loss: 2.4288 - val_accuracy: 0.5529\n",
      "Epoch 506/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0473 - accuracy: 0.9734 - val_loss: 2.4200 - val_accuracy: 0.5526\n",
      "Epoch 507/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0468 - accuracy: 0.9730 - val_loss: 2.4293 - val_accuracy: 0.5529\n",
      "Epoch 508/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0459 - accuracy: 0.9736 - val_loss: 2.4499 - val_accuracy: 0.5504\n",
      "Epoch 509/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0476 - accuracy: 0.9735 - val_loss: 2.4252 - val_accuracy: 0.5490\n",
      "Epoch 510/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0476 - accuracy: 0.9738 - val_loss: 2.4345 - val_accuracy: 0.5515\n",
      "Epoch 511/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0465 - accuracy: 0.9738 - val_loss: 2.4387 - val_accuracy: 0.5529\n",
      "Epoch 512/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0493 - accuracy: 0.9729 - val_loss: 2.4278 - val_accuracy: 0.5526\n",
      "Epoch 513/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0461 - accuracy: 0.9733 - val_loss: 2.4471 - val_accuracy: 0.5515\n",
      "Epoch 514/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0480 - accuracy: 0.9714 - val_loss: 2.4347 - val_accuracy: 0.5490\n",
      "Epoch 515/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0472 - accuracy: 0.9740 - val_loss: 2.4262 - val_accuracy: 0.5507\n",
      "Epoch 516/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0476 - accuracy: 0.9743 - val_loss: 2.4337 - val_accuracy: 0.5507\n",
      "Epoch 517/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0463 - accuracy: 0.9742 - val_loss: 2.4153 - val_accuracy: 0.5521\n",
      "Epoch 518/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0487 - accuracy: 0.9710 - val_loss: 2.4166 - val_accuracy: 0.5493\n",
      "Epoch 519/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0488 - accuracy: 0.9720 - val_loss: 2.4164 - val_accuracy: 0.5495\n",
      "Epoch 520/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0468 - accuracy: 0.9747 - val_loss: 2.4328 - val_accuracy: 0.5476\n",
      "Epoch 521/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0477 - accuracy: 0.9739 - val_loss: 2.4253 - val_accuracy: 0.5493\n",
      "Epoch 522/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0472 - accuracy: 0.9757 - val_loss: 2.4351 - val_accuracy: 0.5512\n",
      "Epoch 523/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0469 - accuracy: 0.9733 - val_loss: 2.4344 - val_accuracy: 0.5512\n",
      "Epoch 524/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0458 - accuracy: 0.9746 - val_loss: 2.4363 - val_accuracy: 0.5510\n",
      "Epoch 525/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0473 - accuracy: 0.9723 - val_loss: 2.4342 - val_accuracy: 0.5557\n",
      "Epoch 526/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0481 - accuracy: 0.9725 - val_loss: 2.4347 - val_accuracy: 0.5566\n",
      "Epoch 527/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0450 - accuracy: 0.9750 - val_loss: 2.4342 - val_accuracy: 0.5552\n",
      "Epoch 528/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0470 - accuracy: 0.9730 - val_loss: 2.4351 - val_accuracy: 0.5524\n",
      "Epoch 529/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0492 - accuracy: 0.9706 - val_loss: 2.4233 - val_accuracy: 0.5574\n",
      "Epoch 530/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0465 - accuracy: 0.9722 - val_loss: 2.4317 - val_accuracy: 0.5560\n",
      "Epoch 531/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0472 - accuracy: 0.9743 - val_loss: 2.4307 - val_accuracy: 0.5512\n",
      "Epoch 532/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0448 - accuracy: 0.9742 - val_loss: 2.4162 - val_accuracy: 0.5566\n",
      "Epoch 533/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0459 - accuracy: 0.9733 - val_loss: 2.4430 - val_accuracy: 0.5521\n",
      "Epoch 534/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0462 - accuracy: 0.9735 - val_loss: 2.4380 - val_accuracy: 0.5518\n",
      "Epoch 535/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0457 - accuracy: 0.9742 - val_loss: 2.4222 - val_accuracy: 0.5549\n",
      "Epoch 536/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0443 - accuracy: 0.9738 - val_loss: 2.4481 - val_accuracy: 0.5512\n",
      "Epoch 537/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0475 - accuracy: 0.9750 - val_loss: 2.4359 - val_accuracy: 0.5560\n",
      "Epoch 538/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0455 - accuracy: 0.9725 - val_loss: 2.4497 - val_accuracy: 0.5535\n",
      "Epoch 539/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0479 - accuracy: 0.9739 - val_loss: 2.4545 - val_accuracy: 0.5560\n",
      "Epoch 540/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0456 - accuracy: 0.9735 - val_loss: 2.4547 - val_accuracy: 0.5555\n",
      "Epoch 541/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0467 - accuracy: 0.9721 - val_loss: 2.4388 - val_accuracy: 0.5535\n",
      "Epoch 542/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0462 - accuracy: 0.9731 - val_loss: 2.4334 - val_accuracy: 0.5541\n",
      "Epoch 543/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0457 - accuracy: 0.9734 - val_loss: 2.4654 - val_accuracy: 0.5552\n",
      "Epoch 544/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0482 - accuracy: 0.9748 - val_loss: 2.4425 - val_accuracy: 0.5481\n",
      "Epoch 545/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0456 - accuracy: 0.9743 - val_loss: 2.4501 - val_accuracy: 0.5490\n",
      "Epoch 546/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0460 - accuracy: 0.9734 - val_loss: 2.4346 - val_accuracy: 0.5490\n",
      "Epoch 547/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0460 - accuracy: 0.9731 - val_loss: 2.4530 - val_accuracy: 0.5498\n",
      "Epoch 548/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0456 - accuracy: 0.9746 - val_loss: 2.4703 - val_accuracy: 0.5487\n",
      "Epoch 549/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0462 - accuracy: 0.9729 - val_loss: 2.4565 - val_accuracy: 0.5549\n",
      "Epoch 550/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0453 - accuracy: 0.9744 - val_loss: 2.4646 - val_accuracy: 0.5560\n",
      "Epoch 551/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0482 - accuracy: 0.9727 - val_loss: 2.4426 - val_accuracy: 0.5591\n",
      "Epoch 552/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0469 - accuracy: 0.9742 - val_loss: 2.4484 - val_accuracy: 0.5498\n",
      "Epoch 553/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0464 - accuracy: 0.9725 - val_loss: 2.4533 - val_accuracy: 0.5495\n",
      "Epoch 554/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0451 - accuracy: 0.9735 - val_loss: 2.4429 - val_accuracy: 0.5504\n",
      "Epoch 555/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0462 - accuracy: 0.9731 - val_loss: 2.4567 - val_accuracy: 0.5498\n",
      "Epoch 556/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0469 - accuracy: 0.9730 - val_loss: 2.4562 - val_accuracy: 0.5507\n",
      "Epoch 557/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0453 - accuracy: 0.9753 - val_loss: 2.4546 - val_accuracy: 0.5572\n",
      "Epoch 558/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0461 - accuracy: 0.9731 - val_loss: 2.4459 - val_accuracy: 0.5521\n",
      "Epoch 559/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0466 - accuracy: 0.9735 - val_loss: 2.4537 - val_accuracy: 0.5552\n",
      "Epoch 560/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0462 - accuracy: 0.9717 - val_loss: 2.4261 - val_accuracy: 0.5569\n",
      "Epoch 561/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0461 - accuracy: 0.9736 - val_loss: 2.4194 - val_accuracy: 0.5566\n",
      "Epoch 562/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0443 - accuracy: 0.9750 - val_loss: 2.4632 - val_accuracy: 0.5557\n",
      "Epoch 563/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0469 - accuracy: 0.9740 - val_loss: 2.4259 - val_accuracy: 0.5577\n",
      "Epoch 564/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0453 - accuracy: 0.9744 - val_loss: 2.4472 - val_accuracy: 0.5546\n",
      "Epoch 565/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0451 - accuracy: 0.9751 - val_loss: 2.4493 - val_accuracy: 0.5493\n",
      "Epoch 566/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0466 - accuracy: 0.9731 - val_loss: 2.4594 - val_accuracy: 0.5526\n",
      "Epoch 567/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0471 - accuracy: 0.9734 - val_loss: 2.4786 - val_accuracy: 0.5538\n",
      "Epoch 568/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0473 - accuracy: 0.9714 - val_loss: 2.4596 - val_accuracy: 0.5526\n",
      "Epoch 569/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0446 - accuracy: 0.9757 - val_loss: 2.4750 - val_accuracy: 0.5512\n",
      "Epoch 570/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0473 - accuracy: 0.9721 - val_loss: 2.4531 - val_accuracy: 0.5501\n",
      "Epoch 571/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0451 - accuracy: 0.9742 - val_loss: 2.4639 - val_accuracy: 0.5518\n",
      "Epoch 572/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0472 - accuracy: 0.9735 - val_loss: 2.4487 - val_accuracy: 0.5515\n",
      "Epoch 573/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0445 - accuracy: 0.9747 - val_loss: 2.4651 - val_accuracy: 0.5526\n",
      "Epoch 574/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0436 - accuracy: 0.9756 - val_loss: 2.4657 - val_accuracy: 0.5521\n",
      "Epoch 575/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0460 - accuracy: 0.9735 - val_loss: 2.4856 - val_accuracy: 0.5552\n",
      "Epoch 576/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0491 - accuracy: 0.9727 - val_loss: 2.4523 - val_accuracy: 0.5538\n",
      "Epoch 577/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0468 - accuracy: 0.9723 - val_loss: 2.4446 - val_accuracy: 0.5586\n",
      "Epoch 578/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0467 - accuracy: 0.9731 - val_loss: 2.4579 - val_accuracy: 0.5518\n",
      "Epoch 579/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0463 - accuracy: 0.9726 - val_loss: 2.4384 - val_accuracy: 0.5538\n",
      "Epoch 580/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0442 - accuracy: 0.9736 - val_loss: 2.4501 - val_accuracy: 0.5555\n",
      "Epoch 581/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0449 - accuracy: 0.9736 - val_loss: 2.4372 - val_accuracy: 0.5518\n",
      "Epoch 582/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0440 - accuracy: 0.9739 - val_loss: 2.4694 - val_accuracy: 0.5529\n",
      "Epoch 583/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0457 - accuracy: 0.9747 - val_loss: 2.4720 - val_accuracy: 0.5476\n",
      "Epoch 584/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0456 - accuracy: 0.9746 - val_loss: 2.4640 - val_accuracy: 0.5566\n",
      "Epoch 585/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0469 - accuracy: 0.9717 - val_loss: 2.4401 - val_accuracy: 0.5555\n",
      "Epoch 586/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0451 - accuracy: 0.9744 - val_loss: 2.4697 - val_accuracy: 0.5521\n",
      "Epoch 587/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0461 - accuracy: 0.9733 - val_loss: 2.4663 - val_accuracy: 0.5535\n",
      "Epoch 588/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0436 - accuracy: 0.9736 - val_loss: 2.4852 - val_accuracy: 0.5549\n",
      "Epoch 589/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0445 - accuracy: 0.9748 - val_loss: 2.4717 - val_accuracy: 0.5521\n",
      "Epoch 590/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0475 - accuracy: 0.9740 - val_loss: 2.4536 - val_accuracy: 0.5521\n",
      "Epoch 591/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0436 - accuracy: 0.9744 - val_loss: 2.4579 - val_accuracy: 0.5515\n",
      "Epoch 592/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0441 - accuracy: 0.9740 - val_loss: 2.4680 - val_accuracy: 0.5557\n",
      "Epoch 593/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0468 - accuracy: 0.9727 - val_loss: 2.4759 - val_accuracy: 0.5515\n",
      "Epoch 594/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0439 - accuracy: 0.9751 - val_loss: 2.4763 - val_accuracy: 0.5535\n",
      "Epoch 595/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0454 - accuracy: 0.9750 - val_loss: 2.4732 - val_accuracy: 0.5515\n",
      "Epoch 596/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0433 - accuracy: 0.9740 - val_loss: 2.4472 - val_accuracy: 0.5583\n",
      "Epoch 597/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0465 - accuracy: 0.9735 - val_loss: 2.4520 - val_accuracy: 0.5557\n",
      "Epoch 598/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0469 - accuracy: 0.9729 - val_loss: 2.4623 - val_accuracy: 0.5507\n",
      "Epoch 599/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0488 - accuracy: 0.9735 - val_loss: 2.4380 - val_accuracy: 0.5529\n",
      "Epoch 600/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0462 - accuracy: 0.9742 - val_loss: 2.4776 - val_accuracy: 0.5563\n",
      "Epoch 601/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0453 - accuracy: 0.9739 - val_loss: 2.4784 - val_accuracy: 0.5566\n",
      "Epoch 602/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0451 - accuracy: 0.9743 - val_loss: 2.4809 - val_accuracy: 0.5560\n",
      "Epoch 603/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0467 - accuracy: 0.9718 - val_loss: 2.4586 - val_accuracy: 0.5552\n",
      "Epoch 604/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0438 - accuracy: 0.9752 - val_loss: 2.4565 - val_accuracy: 0.5560\n",
      "Epoch 605/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0445 - accuracy: 0.9747 - val_loss: 2.4579 - val_accuracy: 0.5549\n",
      "Epoch 606/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0437 - accuracy: 0.9744 - val_loss: 2.4584 - val_accuracy: 0.5543\n",
      "Epoch 607/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0453 - accuracy: 0.9736 - val_loss: 2.4517 - val_accuracy: 0.5552\n",
      "Epoch 608/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0458 - accuracy: 0.9738 - val_loss: 2.4443 - val_accuracy: 0.5574\n",
      "Epoch 609/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0439 - accuracy: 0.9753 - val_loss: 2.4698 - val_accuracy: 0.5510\n",
      "Epoch 610/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0416 - accuracy: 0.9759 - val_loss: 2.4623 - val_accuracy: 0.5538\n",
      "Epoch 611/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0433 - accuracy: 0.9756 - val_loss: 2.4734 - val_accuracy: 0.5515\n",
      "Epoch 612/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0463 - accuracy: 0.9739 - val_loss: 2.4854 - val_accuracy: 0.5493\n",
      "Epoch 613/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0459 - accuracy: 0.9731 - val_loss: 2.4629 - val_accuracy: 0.5487\n",
      "Epoch 614/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0435 - accuracy: 0.9746 - val_loss: 2.4780 - val_accuracy: 0.5473\n",
      "Epoch 615/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0458 - accuracy: 0.9736 - val_loss: 2.4751 - val_accuracy: 0.5481\n",
      "Epoch 616/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0455 - accuracy: 0.9742 - val_loss: 2.4501 - val_accuracy: 0.5510\n",
      "Epoch 617/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0459 - accuracy: 0.9738 - val_loss: 2.4583 - val_accuracy: 0.5481\n",
      "Epoch 618/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0458 - accuracy: 0.9727 - val_loss: 2.4594 - val_accuracy: 0.5467\n",
      "Epoch 619/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0444 - accuracy: 0.9750 - val_loss: 2.4640 - val_accuracy: 0.5521\n",
      "Epoch 620/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0435 - accuracy: 0.9753 - val_loss: 2.4628 - val_accuracy: 0.5524\n",
      "Epoch 621/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0441 - accuracy: 0.9752 - val_loss: 2.4757 - val_accuracy: 0.5521\n",
      "Epoch 622/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0460 - accuracy: 0.9720 - val_loss: 2.4604 - val_accuracy: 0.5529\n",
      "Epoch 623/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0439 - accuracy: 0.9752 - val_loss: 2.4433 - val_accuracy: 0.5538\n",
      "Epoch 624/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0455 - accuracy: 0.9750 - val_loss: 2.4529 - val_accuracy: 0.5524\n",
      "Epoch 625/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0451 - accuracy: 0.9752 - val_loss: 2.4600 - val_accuracy: 0.5560\n",
      "Epoch 626/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0447 - accuracy: 0.9743 - val_loss: 2.4794 - val_accuracy: 0.5518\n",
      "Epoch 627/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0460 - accuracy: 0.9744 - val_loss: 2.4761 - val_accuracy: 0.5538\n",
      "Epoch 628/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0459 - accuracy: 0.9731 - val_loss: 2.4620 - val_accuracy: 0.5524\n",
      "Epoch 629/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0447 - accuracy: 0.9731 - val_loss: 2.4701 - val_accuracy: 0.5535\n",
      "Epoch 630/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0436 - accuracy: 0.9730 - val_loss: 2.4530 - val_accuracy: 0.5535\n",
      "Epoch 631/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0437 - accuracy: 0.9751 - val_loss: 2.4872 - val_accuracy: 0.5557\n",
      "Epoch 632/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0456 - accuracy: 0.9746 - val_loss: 2.4767 - val_accuracy: 0.5510\n",
      "Epoch 633/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0451 - accuracy: 0.9735 - val_loss: 2.4768 - val_accuracy: 0.5549\n",
      "Epoch 634/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0435 - accuracy: 0.9739 - val_loss: 2.4715 - val_accuracy: 0.5538\n",
      "Epoch 635/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0437 - accuracy: 0.9748 - val_loss: 2.4797 - val_accuracy: 0.5510\n",
      "Epoch 636/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0456 - accuracy: 0.9721 - val_loss: 2.4917 - val_accuracy: 0.5512\n",
      "Epoch 637/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0446 - accuracy: 0.9742 - val_loss: 2.4761 - val_accuracy: 0.5532\n",
      "Epoch 638/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0436 - accuracy: 0.9736 - val_loss: 2.4614 - val_accuracy: 0.5518\n",
      "Epoch 639/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0440 - accuracy: 0.9739 - val_loss: 2.4667 - val_accuracy: 0.5524\n",
      "Epoch 640/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0446 - accuracy: 0.9746 - val_loss: 2.4740 - val_accuracy: 0.5546\n",
      "Epoch 641/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0455 - accuracy: 0.9725 - val_loss: 2.4771 - val_accuracy: 0.5543\n",
      "Epoch 642/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0456 - accuracy: 0.9729 - val_loss: 2.4683 - val_accuracy: 0.5549\n",
      "Epoch 643/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0431 - accuracy: 0.9733 - val_loss: 2.4669 - val_accuracy: 0.5543\n",
      "Epoch 644/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0434 - accuracy: 0.9742 - val_loss: 2.4735 - val_accuracy: 0.5538\n",
      "Epoch 645/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0435 - accuracy: 0.9742 - val_loss: 2.4950 - val_accuracy: 0.5577\n",
      "Epoch 646/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0444 - accuracy: 0.9725 - val_loss: 2.4963 - val_accuracy: 0.5552\n",
      "Epoch 647/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0440 - accuracy: 0.9727 - val_loss: 2.4944 - val_accuracy: 0.5484\n",
      "Epoch 648/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0431 - accuracy: 0.9742 - val_loss: 2.4992 - val_accuracy: 0.5515\n",
      "Epoch 649/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0443 - accuracy: 0.9748 - val_loss: 2.4897 - val_accuracy: 0.5552\n",
      "Epoch 650/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0441 - accuracy: 0.9752 - val_loss: 2.4649 - val_accuracy: 0.5532\n",
      "Epoch 651/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0452 - accuracy: 0.9714 - val_loss: 2.4934 - val_accuracy: 0.5501\n",
      "Epoch 652/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0436 - accuracy: 0.9738 - val_loss: 2.4762 - val_accuracy: 0.5541\n",
      "Epoch 653/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0441 - accuracy: 0.9736 - val_loss: 2.4803 - val_accuracy: 0.5479\n",
      "Epoch 654/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0438 - accuracy: 0.9736 - val_loss: 2.4759 - val_accuracy: 0.5507\n",
      "Epoch 655/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0432 - accuracy: 0.9748 - val_loss: 2.4656 - val_accuracy: 0.5538\n",
      "Epoch 656/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0444 - accuracy: 0.9742 - val_loss: 2.4775 - val_accuracy: 0.5529\n",
      "Epoch 657/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0474 - accuracy: 0.9738 - val_loss: 2.4497 - val_accuracy: 0.5512\n",
      "Epoch 658/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0448 - accuracy: 0.9730 - val_loss: 2.4878 - val_accuracy: 0.5498\n",
      "Epoch 659/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0431 - accuracy: 0.9746 - val_loss: 2.4946 - val_accuracy: 0.5532\n",
      "Epoch 660/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0433 - accuracy: 0.9736 - val_loss: 2.4860 - val_accuracy: 0.5510\n",
      "Epoch 661/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0459 - accuracy: 0.9723 - val_loss: 2.5043 - val_accuracy: 0.5569\n",
      "Epoch 662/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0460 - accuracy: 0.9725 - val_loss: 2.4719 - val_accuracy: 0.5524\n",
      "Epoch 663/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0436 - accuracy: 0.9734 - val_loss: 2.4827 - val_accuracy: 0.5552\n",
      "Epoch 664/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0429 - accuracy: 0.9735 - val_loss: 2.5021 - val_accuracy: 0.5549\n",
      "Epoch 665/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0440 - accuracy: 0.9739 - val_loss: 2.4962 - val_accuracy: 0.5487\n",
      "Epoch 666/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0447 - accuracy: 0.9735 - val_loss: 2.4969 - val_accuracy: 0.5504\n",
      "Epoch 667/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0448 - accuracy: 0.9750 - val_loss: 2.4741 - val_accuracy: 0.5549\n",
      "Epoch 668/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0445 - accuracy: 0.9736 - val_loss: 2.4814 - val_accuracy: 0.5490\n",
      "Epoch 669/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0438 - accuracy: 0.9727 - val_loss: 2.4805 - val_accuracy: 0.5518\n",
      "Epoch 670/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0439 - accuracy: 0.9747 - val_loss: 2.4630 - val_accuracy: 0.5526\n",
      "Epoch 671/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0430 - accuracy: 0.9748 - val_loss: 2.4867 - val_accuracy: 0.5498\n",
      "Epoch 672/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0427 - accuracy: 0.9742 - val_loss: 2.4889 - val_accuracy: 0.5524\n",
      "Epoch 673/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0425 - accuracy: 0.9739 - val_loss: 2.5063 - val_accuracy: 0.5510\n",
      "Epoch 674/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0432 - accuracy: 0.9759 - val_loss: 2.5000 - val_accuracy: 0.5518\n",
      "Epoch 675/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0432 - accuracy: 0.9739 - val_loss: 2.4976 - val_accuracy: 0.5470\n",
      "Epoch 676/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0441 - accuracy: 0.9742 - val_loss: 2.4920 - val_accuracy: 0.5507\n",
      "Epoch 677/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0422 - accuracy: 0.9755 - val_loss: 2.5270 - val_accuracy: 0.5456\n",
      "Epoch 678/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0436 - accuracy: 0.9736 - val_loss: 2.5039 - val_accuracy: 0.5510\n",
      "Epoch 679/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0460 - accuracy: 0.9735 - val_loss: 2.4852 - val_accuracy: 0.5484\n",
      "Epoch 680/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0454 - accuracy: 0.9723 - val_loss: 2.4941 - val_accuracy: 0.5453\n",
      "Epoch 681/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0445 - accuracy: 0.9751 - val_loss: 2.4742 - val_accuracy: 0.5510\n",
      "Epoch 682/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0414 - accuracy: 0.9752 - val_loss: 2.4948 - val_accuracy: 0.5479\n",
      "Epoch 683/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0437 - accuracy: 0.9746 - val_loss: 2.4883 - val_accuracy: 0.5465\n",
      "Epoch 684/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0424 - accuracy: 0.9742 - val_loss: 2.4980 - val_accuracy: 0.5484\n",
      "Epoch 685/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0434 - accuracy: 0.9742 - val_loss: 2.4953 - val_accuracy: 0.5501\n",
      "Epoch 686/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0429 - accuracy: 0.9759 - val_loss: 2.5035 - val_accuracy: 0.5512\n",
      "Epoch 687/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0444 - accuracy: 0.9735 - val_loss: 2.5079 - val_accuracy: 0.5490\n",
      "Epoch 688/1000\n",
      "240/240 [==============================] - 70s 292ms/step - loss: 0.0444 - accuracy: 0.9735 - val_loss: 2.5048 - val_accuracy: 0.5515\n",
      "Epoch 689/1000\n",
      "240/240 [==============================] - 71s 295ms/step - loss: 0.0432 - accuracy: 0.9752 - val_loss: 2.5100 - val_accuracy: 0.5481\n",
      "Epoch 690/1000\n",
      "240/240 [==============================] - 71s 295ms/step - loss: 0.0444 - accuracy: 0.9730 - val_loss: 2.4915 - val_accuracy: 0.5479\n",
      "Epoch 691/1000\n",
      "240/240 [==============================] - 71s 295ms/step - loss: 0.0428 - accuracy: 0.9747 - val_loss: 2.4981 - val_accuracy: 0.5518\n",
      "Epoch 692/1000\n",
      "240/240 [==============================] - 71s 296ms/step - loss: 0.0425 - accuracy: 0.9751 - val_loss: 2.5267 - val_accuracy: 0.5504\n",
      "Epoch 693/1000\n",
      "240/240 [==============================] - 71s 297ms/step - loss: 0.0446 - accuracy: 0.9738 - val_loss: 2.4982 - val_accuracy: 0.5532\n",
      "Epoch 694/1000\n",
      "240/240 [==============================] - 70s 293ms/step - loss: 0.0426 - accuracy: 0.9736 - val_loss: 2.5153 - val_accuracy: 0.5532\n",
      "Epoch 695/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0428 - accuracy: 0.9750 - val_loss: 2.5010 - val_accuracy: 0.5543\n",
      "Epoch 696/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0465 - accuracy: 0.9722 - val_loss: 2.5118 - val_accuracy: 0.5535\n",
      "Epoch 697/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0431 - accuracy: 0.9740 - val_loss: 2.5069 - val_accuracy: 0.5572\n",
      "Epoch 698/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0429 - accuracy: 0.9740 - val_loss: 2.5107 - val_accuracy: 0.5526\n",
      "Epoch 699/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0440 - accuracy: 0.9736 - val_loss: 2.5133 - val_accuracy: 0.5512\n",
      "Epoch 700/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0427 - accuracy: 0.9753 - val_loss: 2.5248 - val_accuracy: 0.5510\n",
      "Epoch 701/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0460 - accuracy: 0.9726 - val_loss: 2.4921 - val_accuracy: 0.5498\n",
      "Epoch 702/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0433 - accuracy: 0.9735 - val_loss: 2.4770 - val_accuracy: 0.5577\n",
      "Epoch 703/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0440 - accuracy: 0.9734 - val_loss: 2.5040 - val_accuracy: 0.5521\n",
      "Epoch 704/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0451 - accuracy: 0.9726 - val_loss: 2.4934 - val_accuracy: 0.5532\n",
      "Epoch 705/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0444 - accuracy: 0.9748 - val_loss: 2.5208 - val_accuracy: 0.5498\n",
      "Epoch 706/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0438 - accuracy: 0.9722 - val_loss: 2.5182 - val_accuracy: 0.5439\n",
      "Epoch 707/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0435 - accuracy: 0.9738 - val_loss: 2.5198 - val_accuracy: 0.5495\n",
      "Epoch 708/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0453 - accuracy: 0.9729 - val_loss: 2.5004 - val_accuracy: 0.5512\n",
      "Epoch 709/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0435 - accuracy: 0.9746 - val_loss: 2.4964 - val_accuracy: 0.5501\n",
      "Epoch 710/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0446 - accuracy: 0.9752 - val_loss: 2.4948 - val_accuracy: 0.5521\n",
      "Epoch 711/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0423 - accuracy: 0.9746 - val_loss: 2.5048 - val_accuracy: 0.5493\n",
      "Epoch 712/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0445 - accuracy: 0.9721 - val_loss: 2.5051 - val_accuracy: 0.5504\n",
      "Epoch 713/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0431 - accuracy: 0.9746 - val_loss: 2.4934 - val_accuracy: 0.5487\n",
      "Epoch 714/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0418 - accuracy: 0.9738 - val_loss: 2.5127 - val_accuracy: 0.5526\n",
      "Epoch 715/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0444 - accuracy: 0.9739 - val_loss: 2.4954 - val_accuracy: 0.5512\n",
      "Epoch 716/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0448 - accuracy: 0.9729 - val_loss: 2.5007 - val_accuracy: 0.5493\n",
      "Epoch 717/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0437 - accuracy: 0.9726 - val_loss: 2.5112 - val_accuracy: 0.5465\n",
      "Epoch 718/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0426 - accuracy: 0.9742 - val_loss: 2.5080 - val_accuracy: 0.5510\n",
      "Epoch 719/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0438 - accuracy: 0.9733 - val_loss: 2.5129 - val_accuracy: 0.5535\n",
      "Epoch 720/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0426 - accuracy: 0.9736 - val_loss: 2.5188 - val_accuracy: 0.5560\n",
      "Epoch 721/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0427 - accuracy: 0.9755 - val_loss: 2.5311 - val_accuracy: 0.5555\n",
      "Epoch 722/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0432 - accuracy: 0.9742 - val_loss: 2.5080 - val_accuracy: 0.5532\n",
      "Epoch 723/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0441 - accuracy: 0.9734 - val_loss: 2.5270 - val_accuracy: 0.5504\n",
      "Epoch 724/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0423 - accuracy: 0.9740 - val_loss: 2.5435 - val_accuracy: 0.5535\n",
      "Epoch 725/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0432 - accuracy: 0.9751 - val_loss: 2.5344 - val_accuracy: 0.5510\n",
      "Epoch 726/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0436 - accuracy: 0.9729 - val_loss: 2.5170 - val_accuracy: 0.5510\n",
      "Epoch 727/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0438 - accuracy: 0.9736 - val_loss: 2.4962 - val_accuracy: 0.5493\n",
      "Epoch 728/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0439 - accuracy: 0.9747 - val_loss: 2.5083 - val_accuracy: 0.5518\n",
      "Epoch 729/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0448 - accuracy: 0.9735 - val_loss: 2.4928 - val_accuracy: 0.5549\n",
      "Epoch 730/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0435 - accuracy: 0.9743 - val_loss: 2.4979 - val_accuracy: 0.5541\n",
      "Epoch 731/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0440 - accuracy: 0.9734 - val_loss: 2.5023 - val_accuracy: 0.5490\n",
      "Epoch 732/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0422 - accuracy: 0.9744 - val_loss: 2.4918 - val_accuracy: 0.5512\n",
      "Epoch 733/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0415 - accuracy: 0.9748 - val_loss: 2.4957 - val_accuracy: 0.5501\n",
      "Epoch 734/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0428 - accuracy: 0.9759 - val_loss: 2.5052 - val_accuracy: 0.5572\n",
      "Epoch 735/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0449 - accuracy: 0.9731 - val_loss: 2.4969 - val_accuracy: 0.5529\n",
      "Epoch 736/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0438 - accuracy: 0.9744 - val_loss: 2.4993 - val_accuracy: 0.5518\n",
      "Epoch 737/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0439 - accuracy: 0.9731 - val_loss: 2.4990 - val_accuracy: 0.5518\n",
      "Epoch 738/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0430 - accuracy: 0.9726 - val_loss: 2.5047 - val_accuracy: 0.5510\n",
      "Epoch 739/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0425 - accuracy: 0.9748 - val_loss: 2.5202 - val_accuracy: 0.5521\n",
      "Epoch 740/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0419 - accuracy: 0.9747 - val_loss: 2.5193 - val_accuracy: 0.5493\n",
      "Epoch 741/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0420 - accuracy: 0.9752 - val_loss: 2.5219 - val_accuracy: 0.5524\n",
      "Epoch 742/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0420 - accuracy: 0.9746 - val_loss: 2.5011 - val_accuracy: 0.5493\n",
      "Epoch 743/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0422 - accuracy: 0.9744 - val_loss: 2.5199 - val_accuracy: 0.5512\n",
      "Epoch 744/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0427 - accuracy: 0.9735 - val_loss: 2.5273 - val_accuracy: 0.5462\n",
      "Epoch 745/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0424 - accuracy: 0.9750 - val_loss: 2.5425 - val_accuracy: 0.5450\n",
      "Epoch 746/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0407 - accuracy: 0.9753 - val_loss: 2.5463 - val_accuracy: 0.5490\n",
      "Epoch 747/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0421 - accuracy: 0.9755 - val_loss: 2.5320 - val_accuracy: 0.5479\n",
      "Epoch 748/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0426 - accuracy: 0.9747 - val_loss: 2.5461 - val_accuracy: 0.5493\n",
      "Epoch 749/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0416 - accuracy: 0.9739 - val_loss: 2.5377 - val_accuracy: 0.5498\n",
      "Epoch 750/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0415 - accuracy: 0.9764 - val_loss: 2.5272 - val_accuracy: 0.5510\n",
      "Epoch 751/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0434 - accuracy: 0.9736 - val_loss: 2.5047 - val_accuracy: 0.5498\n",
      "Epoch 752/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0432 - accuracy: 0.9729 - val_loss: 2.5153 - val_accuracy: 0.5510\n",
      "Epoch 753/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0411 - accuracy: 0.9748 - val_loss: 2.5140 - val_accuracy: 0.5515\n",
      "Epoch 754/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0423 - accuracy: 0.9748 - val_loss: 2.5246 - val_accuracy: 0.5518\n",
      "Epoch 755/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0422 - accuracy: 0.9733 - val_loss: 2.5087 - val_accuracy: 0.5507\n",
      "Epoch 756/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0423 - accuracy: 0.9757 - val_loss: 2.5206 - val_accuracy: 0.5470\n",
      "Epoch 757/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0433 - accuracy: 0.9739 - val_loss: 2.5114 - val_accuracy: 0.5470\n",
      "Epoch 758/1000\n",
      "240/240 [==============================] - 68s 284ms/step - loss: 0.0417 - accuracy: 0.9750 - val_loss: 2.5183 - val_accuracy: 0.5473\n",
      "Epoch 759/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0431 - accuracy: 0.9733 - val_loss: 2.5239 - val_accuracy: 0.5515\n",
      "Epoch 760/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0427 - accuracy: 0.9752 - val_loss: 2.5244 - val_accuracy: 0.5476\n",
      "Epoch 761/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0434 - accuracy: 0.9750 - val_loss: 2.4984 - val_accuracy: 0.5481\n",
      "Epoch 762/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0419 - accuracy: 0.9760 - val_loss: 2.4994 - val_accuracy: 0.5504\n",
      "Epoch 763/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0436 - accuracy: 0.9744 - val_loss: 2.5184 - val_accuracy: 0.5501\n",
      "Epoch 764/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0426 - accuracy: 0.9748 - val_loss: 2.5186 - val_accuracy: 0.5504\n",
      "Epoch 765/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0436 - accuracy: 0.9738 - val_loss: 2.5208 - val_accuracy: 0.5515\n",
      "Epoch 766/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0426 - accuracy: 0.9735 - val_loss: 2.5031 - val_accuracy: 0.5510\n",
      "Epoch 767/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0443 - accuracy: 0.9730 - val_loss: 2.5201 - val_accuracy: 0.5512\n",
      "Epoch 768/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0442 - accuracy: 0.9743 - val_loss: 2.5401 - val_accuracy: 0.5473\n",
      "Epoch 769/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0440 - accuracy: 0.9740 - val_loss: 2.5155 - val_accuracy: 0.5501\n",
      "Epoch 770/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0428 - accuracy: 0.9740 - val_loss: 2.5183 - val_accuracy: 0.5476\n",
      "Epoch 771/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0426 - accuracy: 0.9743 - val_loss: 2.5064 - val_accuracy: 0.5532\n",
      "Epoch 772/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0426 - accuracy: 0.9744 - val_loss: 2.5012 - val_accuracy: 0.5515\n",
      "Epoch 773/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0424 - accuracy: 0.9735 - val_loss: 2.5059 - val_accuracy: 0.5546\n",
      "Epoch 774/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0434 - accuracy: 0.9720 - val_loss: 2.5206 - val_accuracy: 0.5504\n",
      "Epoch 775/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0428 - accuracy: 0.9747 - val_loss: 2.5190 - val_accuracy: 0.5512\n",
      "Epoch 776/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0438 - accuracy: 0.9736 - val_loss: 2.5069 - val_accuracy: 0.5555\n",
      "Epoch 777/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0421 - accuracy: 0.9750 - val_loss: 2.5159 - val_accuracy: 0.5538\n",
      "Epoch 778/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0419 - accuracy: 0.9746 - val_loss: 2.5282 - val_accuracy: 0.5510\n",
      "Epoch 779/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0411 - accuracy: 0.9729 - val_loss: 2.5315 - val_accuracy: 0.5526\n",
      "Epoch 780/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0425 - accuracy: 0.9740 - val_loss: 2.5304 - val_accuracy: 0.5518\n",
      "Epoch 781/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0427 - accuracy: 0.9743 - val_loss: 2.5456 - val_accuracy: 0.5507\n",
      "Epoch 782/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0408 - accuracy: 0.9739 - val_loss: 2.5331 - val_accuracy: 0.5524\n",
      "Epoch 783/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0425 - accuracy: 0.9751 - val_loss: 2.5426 - val_accuracy: 0.5470\n",
      "Epoch 784/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0432 - accuracy: 0.9723 - val_loss: 2.5441 - val_accuracy: 0.5510\n",
      "Epoch 785/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0429 - accuracy: 0.9742 - val_loss: 2.5316 - val_accuracy: 0.5510\n",
      "Epoch 786/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0436 - accuracy: 0.9730 - val_loss: 2.5076 - val_accuracy: 0.5552\n",
      "Epoch 787/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0416 - accuracy: 0.9746 - val_loss: 2.5292 - val_accuracy: 0.5473\n",
      "Epoch 788/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0435 - accuracy: 0.9739 - val_loss: 2.5134 - val_accuracy: 0.5504\n",
      "Epoch 789/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0415 - accuracy: 0.9756 - val_loss: 2.5164 - val_accuracy: 0.5493\n",
      "Epoch 790/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0420 - accuracy: 0.9746 - val_loss: 2.5119 - val_accuracy: 0.5501\n",
      "Epoch 791/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0423 - accuracy: 0.9731 - val_loss: 2.5170 - val_accuracy: 0.5479\n",
      "Epoch 792/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0429 - accuracy: 0.9735 - val_loss: 2.5030 - val_accuracy: 0.5538\n",
      "Epoch 793/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0420 - accuracy: 0.9751 - val_loss: 2.5222 - val_accuracy: 0.5493\n",
      "Epoch 794/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0420 - accuracy: 0.9755 - val_loss: 2.5198 - val_accuracy: 0.5529\n",
      "Epoch 795/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0428 - accuracy: 0.9736 - val_loss: 2.5144 - val_accuracy: 0.5583\n",
      "Epoch 796/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0411 - accuracy: 0.9740 - val_loss: 2.5135 - val_accuracy: 0.5586\n",
      "Epoch 797/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0409 - accuracy: 0.9744 - val_loss: 2.5527 - val_accuracy: 0.5532\n",
      "Epoch 798/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0411 - accuracy: 0.9755 - val_loss: 2.5468 - val_accuracy: 0.5546\n",
      "Epoch 799/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0404 - accuracy: 0.9746 - val_loss: 2.5662 - val_accuracy: 0.5515\n",
      "Epoch 800/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0423 - accuracy: 0.9740 - val_loss: 2.5480 - val_accuracy: 0.5501\n",
      "Epoch 801/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0434 - accuracy: 0.9739 - val_loss: 2.5186 - val_accuracy: 0.5541\n",
      "Epoch 802/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0413 - accuracy: 0.9746 - val_loss: 2.5350 - val_accuracy: 0.5569\n",
      "Epoch 803/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0425 - accuracy: 0.9731 - val_loss: 2.5126 - val_accuracy: 0.5549\n",
      "Epoch 804/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0420 - accuracy: 0.9738 - val_loss: 2.5309 - val_accuracy: 0.5479\n",
      "Epoch 805/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0401 - accuracy: 0.9772 - val_loss: 2.5482 - val_accuracy: 0.5495\n",
      "Epoch 806/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0425 - accuracy: 0.9736 - val_loss: 2.5464 - val_accuracy: 0.5484\n",
      "Epoch 807/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0429 - accuracy: 0.9725 - val_loss: 2.5403 - val_accuracy: 0.5526\n",
      "Epoch 808/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0429 - accuracy: 0.9743 - val_loss: 2.5502 - val_accuracy: 0.5524\n",
      "Epoch 809/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0434 - accuracy: 0.9726 - val_loss: 2.5380 - val_accuracy: 0.5524\n",
      "Epoch 810/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0406 - accuracy: 0.9757 - val_loss: 2.5397 - val_accuracy: 0.5524\n",
      "Epoch 811/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0418 - accuracy: 0.9760 - val_loss: 2.5550 - val_accuracy: 0.5524\n",
      "Epoch 812/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0425 - accuracy: 0.9746 - val_loss: 2.5462 - val_accuracy: 0.5521\n",
      "Epoch 813/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0421 - accuracy: 0.9743 - val_loss: 2.5472 - val_accuracy: 0.5532\n",
      "Epoch 814/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0413 - accuracy: 0.9747 - val_loss: 2.5493 - val_accuracy: 0.5569\n",
      "Epoch 815/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0416 - accuracy: 0.9746 - val_loss: 2.5439 - val_accuracy: 0.5507\n",
      "Epoch 816/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0423 - accuracy: 0.9740 - val_loss: 2.5379 - val_accuracy: 0.5462\n",
      "Epoch 817/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0428 - accuracy: 0.9725 - val_loss: 2.5423 - val_accuracy: 0.5512\n",
      "Epoch 818/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0407 - accuracy: 0.9743 - val_loss: 2.5388 - val_accuracy: 0.5507\n",
      "Epoch 819/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0426 - accuracy: 0.9738 - val_loss: 2.5238 - val_accuracy: 0.5504\n",
      "Epoch 820/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0429 - accuracy: 0.9744 - val_loss: 2.5337 - val_accuracy: 0.5512\n",
      "Epoch 821/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0417 - accuracy: 0.9740 - val_loss: 2.5408 - val_accuracy: 0.5481\n",
      "Epoch 822/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0429 - accuracy: 0.9742 - val_loss: 2.5348 - val_accuracy: 0.5495\n",
      "Epoch 823/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0405 - accuracy: 0.9751 - val_loss: 2.5462 - val_accuracy: 0.5495\n",
      "Epoch 824/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0425 - accuracy: 0.9742 - val_loss: 2.5423 - val_accuracy: 0.5518\n",
      "Epoch 825/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0417 - accuracy: 0.9746 - val_loss: 2.5301 - val_accuracy: 0.5495\n",
      "Epoch 826/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0428 - accuracy: 0.9746 - val_loss: 2.5363 - val_accuracy: 0.5476\n",
      "Epoch 827/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0417 - accuracy: 0.9731 - val_loss: 2.5422 - val_accuracy: 0.5493\n",
      "Epoch 828/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0425 - accuracy: 0.9736 - val_loss: 2.5334 - val_accuracy: 0.5479\n",
      "Epoch 829/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0427 - accuracy: 0.9747 - val_loss: 2.5131 - val_accuracy: 0.5552\n",
      "Epoch 830/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0403 - accuracy: 0.9755 - val_loss: 2.5334 - val_accuracy: 0.5504\n",
      "Epoch 831/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0400 - accuracy: 0.9764 - val_loss: 2.5435 - val_accuracy: 0.5515\n",
      "Epoch 832/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0418 - accuracy: 0.9753 - val_loss: 2.5463 - val_accuracy: 0.5512\n",
      "Epoch 833/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0409 - accuracy: 0.9752 - val_loss: 2.5429 - val_accuracy: 0.5515\n",
      "Epoch 834/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0414 - accuracy: 0.9744 - val_loss: 2.5425 - val_accuracy: 0.5518\n",
      "Epoch 835/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0423 - accuracy: 0.9738 - val_loss: 2.5616 - val_accuracy: 0.5504\n",
      "Epoch 836/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0426 - accuracy: 0.9750 - val_loss: 2.5604 - val_accuracy: 0.5557\n",
      "Epoch 837/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0418 - accuracy: 0.9739 - val_loss: 2.5517 - val_accuracy: 0.5535\n",
      "Epoch 838/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0415 - accuracy: 0.9736 - val_loss: 2.5514 - val_accuracy: 0.5572\n",
      "Epoch 839/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0408 - accuracy: 0.9751 - val_loss: 2.5448 - val_accuracy: 0.5515\n",
      "Epoch 840/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0418 - accuracy: 0.9752 - val_loss: 2.5301 - val_accuracy: 0.5493\n",
      "Epoch 841/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0414 - accuracy: 0.9751 - val_loss: 2.5514 - val_accuracy: 0.5501\n",
      "Epoch 842/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0405 - accuracy: 0.9744 - val_loss: 2.5488 - val_accuracy: 0.5512\n",
      "Epoch 843/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0416 - accuracy: 0.9742 - val_loss: 2.5659 - val_accuracy: 0.5465\n",
      "Epoch 844/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0399 - accuracy: 0.9752 - val_loss: 2.5893 - val_accuracy: 0.5456\n",
      "Epoch 845/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0420 - accuracy: 0.9738 - val_loss: 2.5680 - val_accuracy: 0.5470\n",
      "Epoch 846/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0417 - accuracy: 0.9742 - val_loss: 2.5515 - val_accuracy: 0.5543\n",
      "Epoch 847/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0414 - accuracy: 0.9755 - val_loss: 2.5471 - val_accuracy: 0.5555\n",
      "Epoch 848/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0418 - accuracy: 0.9736 - val_loss: 2.5571 - val_accuracy: 0.5462\n",
      "Epoch 849/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0407 - accuracy: 0.9743 - val_loss: 2.5853 - val_accuracy: 0.5487\n",
      "Epoch 850/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0419 - accuracy: 0.9726 - val_loss: 2.5605 - val_accuracy: 0.5450\n",
      "Epoch 851/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0416 - accuracy: 0.9750 - val_loss: 2.5552 - val_accuracy: 0.5501\n",
      "Epoch 852/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0415 - accuracy: 0.9735 - val_loss: 2.5533 - val_accuracy: 0.5459\n",
      "Epoch 853/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0408 - accuracy: 0.9761 - val_loss: 2.5487 - val_accuracy: 0.5538\n",
      "Epoch 854/1000\n",
      "240/240 [==============================] - 69s 285ms/step - loss: 0.0418 - accuracy: 0.9755 - val_loss: 2.5416 - val_accuracy: 0.5526\n",
      "Epoch 855/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0410 - accuracy: 0.9740 - val_loss: 2.5333 - val_accuracy: 0.5543\n",
      "Epoch 856/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0396 - accuracy: 0.9763 - val_loss: 2.5640 - val_accuracy: 0.5529\n",
      "Epoch 857/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0424 - accuracy: 0.9747 - val_loss: 2.5627 - val_accuracy: 0.5521\n",
      "Epoch 858/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0414 - accuracy: 0.9751 - val_loss: 2.5689 - val_accuracy: 0.5512\n",
      "Epoch 859/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0413 - accuracy: 0.9760 - val_loss: 2.5606 - val_accuracy: 0.5493\n",
      "Epoch 860/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0419 - accuracy: 0.9752 - val_loss: 2.5571 - val_accuracy: 0.5495\n",
      "Epoch 861/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0422 - accuracy: 0.9731 - val_loss: 2.5581 - val_accuracy: 0.5504\n",
      "Epoch 862/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0418 - accuracy: 0.9742 - val_loss: 2.5629 - val_accuracy: 0.5504\n",
      "Epoch 863/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0424 - accuracy: 0.9731 - val_loss: 2.5446 - val_accuracy: 0.5490\n",
      "Epoch 864/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0399 - accuracy: 0.9759 - val_loss: 2.5558 - val_accuracy: 0.5507\n",
      "Epoch 865/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0416 - accuracy: 0.9740 - val_loss: 2.5733 - val_accuracy: 0.5526\n",
      "Epoch 866/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0413 - accuracy: 0.9746 - val_loss: 2.5687 - val_accuracy: 0.5512\n",
      "Epoch 867/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0407 - accuracy: 0.9752 - val_loss: 2.5618 - val_accuracy: 0.5524\n",
      "Epoch 868/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0397 - accuracy: 0.9751 - val_loss: 2.5685 - val_accuracy: 0.5515\n",
      "Epoch 869/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0407 - accuracy: 0.9757 - val_loss: 2.5559 - val_accuracy: 0.5481\n",
      "Epoch 870/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0413 - accuracy: 0.9747 - val_loss: 2.5678 - val_accuracy: 0.5481\n",
      "Epoch 871/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0425 - accuracy: 0.9747 - val_loss: 2.5644 - val_accuracy: 0.5507\n",
      "Epoch 872/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0403 - accuracy: 0.9743 - val_loss: 2.5743 - val_accuracy: 0.5481\n",
      "Epoch 873/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0408 - accuracy: 0.9742 - val_loss: 2.5814 - val_accuracy: 0.5507\n",
      "Epoch 874/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0432 - accuracy: 0.9726 - val_loss: 2.5480 - val_accuracy: 0.5543\n",
      "Epoch 875/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0409 - accuracy: 0.9748 - val_loss: 2.5654 - val_accuracy: 0.5495\n",
      "Epoch 876/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0426 - accuracy: 0.9735 - val_loss: 2.5830 - val_accuracy: 0.5518\n",
      "Epoch 877/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0408 - accuracy: 0.9731 - val_loss: 2.5679 - val_accuracy: 0.5518\n",
      "Epoch 878/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0424 - accuracy: 0.9751 - val_loss: 2.5602 - val_accuracy: 0.5481\n",
      "Epoch 879/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0431 - accuracy: 0.9743 - val_loss: 2.5562 - val_accuracy: 0.5510\n",
      "Epoch 880/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0418 - accuracy: 0.9735 - val_loss: 2.5725 - val_accuracy: 0.5493\n",
      "Epoch 881/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0418 - accuracy: 0.9736 - val_loss: 2.5661 - val_accuracy: 0.5507\n",
      "Epoch 882/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0393 - accuracy: 0.9753 - val_loss: 2.5865 - val_accuracy: 0.5507\n",
      "Epoch 883/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0410 - accuracy: 0.9760 - val_loss: 2.5668 - val_accuracy: 0.5518\n",
      "Epoch 884/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0406 - accuracy: 0.9756 - val_loss: 2.5807 - val_accuracy: 0.5532\n",
      "Epoch 885/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0410 - accuracy: 0.9746 - val_loss: 2.5714 - val_accuracy: 0.5535\n",
      "Epoch 886/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0408 - accuracy: 0.9751 - val_loss: 2.5902 - val_accuracy: 0.5549\n",
      "Epoch 887/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0421 - accuracy: 0.9748 - val_loss: 2.5604 - val_accuracy: 0.5507\n",
      "Epoch 888/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0391 - accuracy: 0.9764 - val_loss: 2.5510 - val_accuracy: 0.5526\n",
      "Epoch 889/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0415 - accuracy: 0.9748 - val_loss: 2.5393 - val_accuracy: 0.5521\n",
      "Epoch 890/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0432 - accuracy: 0.9729 - val_loss: 2.5403 - val_accuracy: 0.5560\n",
      "Epoch 891/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0396 - accuracy: 0.9760 - val_loss: 2.5637 - val_accuracy: 0.5512\n",
      "Epoch 892/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0415 - accuracy: 0.9721 - val_loss: 2.5852 - val_accuracy: 0.5481\n",
      "Epoch 893/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0417 - accuracy: 0.9742 - val_loss: 2.5914 - val_accuracy: 0.5501\n",
      "Epoch 894/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0402 - accuracy: 0.9744 - val_loss: 2.5733 - val_accuracy: 0.5501\n",
      "Epoch 895/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0409 - accuracy: 0.9742 - val_loss: 2.5781 - val_accuracy: 0.5465\n",
      "Epoch 896/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0433 - accuracy: 0.9734 - val_loss: 2.5756 - val_accuracy: 0.5495\n",
      "Epoch 897/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0415 - accuracy: 0.9731 - val_loss: 2.5722 - val_accuracy: 0.5493\n",
      "Epoch 898/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0411 - accuracy: 0.9757 - val_loss: 2.5798 - val_accuracy: 0.5470\n",
      "Epoch 899/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0428 - accuracy: 0.9727 - val_loss: 2.5906 - val_accuracy: 0.5431\n",
      "Epoch 900/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0400 - accuracy: 0.9761 - val_loss: 2.5962 - val_accuracy: 0.5470\n",
      "Epoch 901/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0427 - accuracy: 0.9739 - val_loss: 2.5694 - val_accuracy: 0.5518\n",
      "Epoch 902/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0420 - accuracy: 0.9751 - val_loss: 2.5794 - val_accuracy: 0.5493\n",
      "Epoch 903/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0427 - accuracy: 0.9738 - val_loss: 2.5905 - val_accuracy: 0.5487\n",
      "Epoch 904/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0403 - accuracy: 0.9747 - val_loss: 2.5780 - val_accuracy: 0.5462\n",
      "Epoch 905/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0403 - accuracy: 0.9761 - val_loss: 2.5687 - val_accuracy: 0.5481\n",
      "Epoch 906/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0434 - accuracy: 0.9730 - val_loss: 2.5772 - val_accuracy: 0.5479\n",
      "Epoch 907/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0420 - accuracy: 0.9743 - val_loss: 2.5692 - val_accuracy: 0.5495\n",
      "Epoch 908/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0402 - accuracy: 0.9752 - val_loss: 2.5853 - val_accuracy: 0.5498\n",
      "Epoch 909/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0425 - accuracy: 0.9744 - val_loss: 2.5698 - val_accuracy: 0.5473\n",
      "Epoch 910/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0414 - accuracy: 0.9740 - val_loss: 2.5858 - val_accuracy: 0.5490\n",
      "Epoch 911/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0414 - accuracy: 0.9753 - val_loss: 2.5882 - val_accuracy: 0.5465\n",
      "Epoch 912/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0400 - accuracy: 0.9744 - val_loss: 2.5796 - val_accuracy: 0.5501\n",
      "Epoch 913/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0429 - accuracy: 0.9734 - val_loss: 2.5794 - val_accuracy: 0.5507\n",
      "Epoch 914/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0408 - accuracy: 0.9757 - val_loss: 2.5847 - val_accuracy: 0.5518\n",
      "Epoch 915/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0401 - accuracy: 0.9750 - val_loss: 2.5757 - val_accuracy: 0.5569\n",
      "Epoch 916/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0406 - accuracy: 0.9740 - val_loss: 2.5888 - val_accuracy: 0.5543\n",
      "Epoch 917/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0421 - accuracy: 0.9733 - val_loss: 2.5762 - val_accuracy: 0.5504\n",
      "Epoch 918/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0405 - accuracy: 0.9756 - val_loss: 2.5744 - val_accuracy: 0.5560\n",
      "Epoch 919/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0405 - accuracy: 0.9738 - val_loss: 2.5810 - val_accuracy: 0.5526\n",
      "Epoch 920/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0425 - accuracy: 0.9731 - val_loss: 2.5749 - val_accuracy: 0.5538\n",
      "Epoch 921/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0409 - accuracy: 0.9748 - val_loss: 2.5743 - val_accuracy: 0.5515\n",
      "Epoch 922/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0421 - accuracy: 0.9733 - val_loss: 2.5714 - val_accuracy: 0.5515\n",
      "Epoch 923/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0393 - accuracy: 0.9760 - val_loss: 2.5842 - val_accuracy: 0.5538\n",
      "Epoch 924/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0414 - accuracy: 0.9739 - val_loss: 2.5939 - val_accuracy: 0.5495\n",
      "Epoch 925/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0409 - accuracy: 0.9747 - val_loss: 2.6258 - val_accuracy: 0.5532\n",
      "Epoch 926/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0413 - accuracy: 0.9746 - val_loss: 2.5975 - val_accuracy: 0.5524\n",
      "Epoch 927/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0404 - accuracy: 0.9755 - val_loss: 2.5980 - val_accuracy: 0.5504\n",
      "Epoch 928/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0408 - accuracy: 0.9746 - val_loss: 2.6029 - val_accuracy: 0.5521\n",
      "Epoch 929/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0416 - accuracy: 0.9752 - val_loss: 2.5988 - val_accuracy: 0.5470\n",
      "Epoch 930/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0404 - accuracy: 0.9757 - val_loss: 2.5946 - val_accuracy: 0.5515\n",
      "Epoch 931/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0416 - accuracy: 0.9736 - val_loss: 2.5996 - val_accuracy: 0.5518\n",
      "Epoch 932/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0404 - accuracy: 0.9766 - val_loss: 2.5920 - val_accuracy: 0.5549\n",
      "Epoch 933/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0389 - accuracy: 0.9764 - val_loss: 2.5935 - val_accuracy: 0.5557\n",
      "Epoch 934/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0409 - accuracy: 0.9765 - val_loss: 2.6022 - val_accuracy: 0.5560\n",
      "Epoch 935/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0428 - accuracy: 0.9713 - val_loss: 2.5893 - val_accuracy: 0.5557\n",
      "Epoch 936/1000\n",
      "240/240 [==============================] - 68s 286ms/step - loss: 0.0412 - accuracy: 0.9752 - val_loss: 2.5795 - val_accuracy: 0.5495\n",
      "Epoch 937/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0405 - accuracy: 0.9761 - val_loss: 2.5782 - val_accuracy: 0.5546\n",
      "Epoch 938/1000\n",
      "240/240 [==============================] - 68s 285ms/step - loss: 0.0405 - accuracy: 0.9750 - val_loss: 2.5779 - val_accuracy: 0.5518\n",
      "Epoch 939/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0401 - accuracy: 0.9742 - val_loss: 2.5903 - val_accuracy: 0.5498\n",
      "Epoch 940/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0400 - accuracy: 0.9748 - val_loss: 2.5884 - val_accuracy: 0.5484\n",
      "Epoch 941/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0418 - accuracy: 0.9739 - val_loss: 2.5743 - val_accuracy: 0.5495\n",
      "Epoch 942/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0401 - accuracy: 0.9752 - val_loss: 2.5580 - val_accuracy: 0.5493\n",
      "Epoch 943/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0409 - accuracy: 0.9752 - val_loss: 2.5787 - val_accuracy: 0.5490\n",
      "Epoch 944/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0424 - accuracy: 0.9740 - val_loss: 2.5890 - val_accuracy: 0.5479\n",
      "Epoch 945/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0428 - accuracy: 0.9730 - val_loss: 2.5835 - val_accuracy: 0.5512\n",
      "Epoch 946/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0409 - accuracy: 0.9751 - val_loss: 2.5698 - val_accuracy: 0.5462\n",
      "Epoch 947/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0401 - accuracy: 0.9756 - val_loss: 2.5598 - val_accuracy: 0.5476\n",
      "Epoch 948/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0403 - accuracy: 0.9742 - val_loss: 2.5727 - val_accuracy: 0.5490\n",
      "Epoch 949/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0404 - accuracy: 0.9736 - val_loss: 2.5911 - val_accuracy: 0.5473\n",
      "Epoch 950/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0410 - accuracy: 0.9747 - val_loss: 2.6002 - val_accuracy: 0.5450\n",
      "Epoch 951/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0413 - accuracy: 0.9738 - val_loss: 2.5770 - val_accuracy: 0.5510\n",
      "Epoch 952/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0402 - accuracy: 0.9740 - val_loss: 2.5840 - val_accuracy: 0.5507\n",
      "Epoch 953/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0403 - accuracy: 0.9735 - val_loss: 2.5966 - val_accuracy: 0.5456\n",
      "Epoch 954/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0408 - accuracy: 0.9750 - val_loss: 2.5905 - val_accuracy: 0.5428\n",
      "Epoch 955/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0423 - accuracy: 0.9746 - val_loss: 2.5609 - val_accuracy: 0.5526\n",
      "Epoch 956/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0400 - accuracy: 0.9747 - val_loss: 2.5682 - val_accuracy: 0.5515\n",
      "Epoch 957/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0401 - accuracy: 0.9759 - val_loss: 2.5724 - val_accuracy: 0.5476\n",
      "Epoch 958/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0412 - accuracy: 0.9729 - val_loss: 2.5683 - val_accuracy: 0.5515\n",
      "Epoch 959/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0408 - accuracy: 0.9746 - val_loss: 2.5822 - val_accuracy: 0.5479\n",
      "Epoch 960/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0417 - accuracy: 0.9753 - val_loss: 2.5681 - val_accuracy: 0.5521\n",
      "Epoch 961/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0399 - accuracy: 0.9756 - val_loss: 2.5798 - val_accuracy: 0.5487\n",
      "Epoch 962/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0409 - accuracy: 0.9756 - val_loss: 2.5890 - val_accuracy: 0.5518\n",
      "Epoch 963/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0399 - accuracy: 0.9753 - val_loss: 2.5764 - val_accuracy: 0.5515\n",
      "Epoch 964/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0392 - accuracy: 0.9763 - val_loss: 2.5952 - val_accuracy: 0.5510\n",
      "Epoch 965/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0408 - accuracy: 0.9730 - val_loss: 2.5682 - val_accuracy: 0.5512\n",
      "Epoch 966/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0404 - accuracy: 0.9757 - val_loss: 2.5656 - val_accuracy: 0.5504\n",
      "Epoch 967/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0423 - accuracy: 0.9744 - val_loss: 2.5962 - val_accuracy: 0.5493\n",
      "Epoch 968/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0404 - accuracy: 0.9748 - val_loss: 2.5723 - val_accuracy: 0.5495\n",
      "Epoch 969/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0410 - accuracy: 0.9740 - val_loss: 2.5744 - val_accuracy: 0.5490\n",
      "Epoch 970/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0400 - accuracy: 0.9742 - val_loss: 2.5942 - val_accuracy: 0.5481\n",
      "Epoch 971/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0411 - accuracy: 0.9752 - val_loss: 2.5883 - val_accuracy: 0.5526\n",
      "Epoch 972/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0400 - accuracy: 0.9751 - val_loss: 2.5862 - val_accuracy: 0.5504\n",
      "Epoch 973/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0391 - accuracy: 0.9753 - val_loss: 2.5903 - val_accuracy: 0.5529\n",
      "Epoch 974/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0396 - accuracy: 0.9751 - val_loss: 2.5896 - val_accuracy: 0.5487\n",
      "Epoch 975/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0389 - accuracy: 0.9751 - val_loss: 2.6013 - val_accuracy: 0.5563\n",
      "Epoch 976/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0407 - accuracy: 0.9747 - val_loss: 2.5879 - val_accuracy: 0.5541\n",
      "Epoch 977/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0398 - accuracy: 0.9753 - val_loss: 2.5842 - val_accuracy: 0.5518\n",
      "Epoch 978/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0422 - accuracy: 0.9739 - val_loss: 2.5948 - val_accuracy: 0.5510\n",
      "Epoch 979/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0412 - accuracy: 0.9734 - val_loss: 2.5772 - val_accuracy: 0.5518\n",
      "Epoch 980/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0432 - accuracy: 0.9722 - val_loss: 2.5624 - val_accuracy: 0.5501\n",
      "Epoch 981/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0389 - accuracy: 0.9765 - val_loss: 2.5867 - val_accuracy: 0.5476\n",
      "Epoch 982/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0413 - accuracy: 0.9736 - val_loss: 2.5826 - val_accuracy: 0.5507\n",
      "Epoch 983/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0396 - accuracy: 0.9776 - val_loss: 2.5943 - val_accuracy: 0.5493\n",
      "Epoch 984/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0404 - accuracy: 0.9747 - val_loss: 2.5775 - val_accuracy: 0.5535\n",
      "Epoch 985/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0382 - accuracy: 0.9759 - val_loss: 2.6027 - val_accuracy: 0.5512\n",
      "Epoch 986/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0405 - accuracy: 0.9750 - val_loss: 2.5942 - val_accuracy: 0.5467\n",
      "Epoch 987/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0405 - accuracy: 0.9757 - val_loss: 2.5950 - val_accuracy: 0.5470\n",
      "Epoch 988/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0407 - accuracy: 0.9755 - val_loss: 2.6114 - val_accuracy: 0.5487\n",
      "Epoch 989/1000\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0419 - accuracy: 0.9733 - val_loss: 2.5880 - val_accuracy: 0.5439\n",
      "Epoch 990/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0425 - accuracy: 0.9744 - val_loss: 2.6035 - val_accuracy: 0.5448\n",
      "Epoch 991/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0406 - accuracy: 0.9738 - val_loss: 2.5785 - val_accuracy: 0.5490\n",
      "Epoch 992/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0417 - accuracy: 0.9760 - val_loss: 2.5882 - val_accuracy: 0.5510\n",
      "Epoch 993/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0405 - accuracy: 0.9750 - val_loss: 2.5876 - val_accuracy: 0.5484\n",
      "Epoch 994/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0410 - accuracy: 0.9742 - val_loss: 2.6058 - val_accuracy: 0.5467\n",
      "Epoch 995/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0396 - accuracy: 0.9765 - val_loss: 2.6062 - val_accuracy: 0.5495\n",
      "Epoch 996/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0419 - accuracy: 0.9740 - val_loss: 2.5890 - val_accuracy: 0.5470\n",
      "Epoch 997/1000\n",
      "240/240 [==============================] - 69s 287ms/step - loss: 0.0387 - accuracy: 0.9761 - val_loss: 2.6088 - val_accuracy: 0.5479\n",
      "Epoch 998/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0410 - accuracy: 0.9750 - val_loss: 2.6076 - val_accuracy: 0.5490\n",
      "Epoch 999/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0407 - accuracy: 0.9733 - val_loss: 2.5998 - val_accuracy: 0.5479\n",
      "Epoch 1000/1000\n",
      "240/240 [==============================] - 69s 286ms/step - loss: 0.0387 - accuracy: 0.9757 - val_loss: 2.6013 - val_accuracy: 0.5512\n",
      "Final Epoch Results:\n",
      "{'loss': 0.03865087777376175, 'accuracy': 0.9757338762283325, 'val_loss': 2.601285457611084, 'val_accuracy': 0.5512387156486511}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 13s 117ms/step\n",
      "Accuracy: 0.5516853932584269\n",
      "Average Precision: 0.5683682850737968\n",
      "Average Recall: 0.5468474483263216\n",
      "Average F1 Score: 0.5410870250919355\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "\n",
    "# Define data directories\n",
    "train_data_dir = r\"C:\\Users\\79894\\Downloads\\archive2_converted_train\"\n",
    "test_data_dir = r\"C:\\Users\\79894\\Downloads\\archive2_converted_test\"\n",
    "\n",
    "# Define data generators with preprocessing_function (fixed image size)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate batches of preprocessed images\n",
    "batch_size = 32\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),  # Adjusted to match the MobileNet model input shape\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(224, 224),  # Adjusted to match the MobileNet model input shape\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load pre-trained MobileNet model without the top classification layer\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of MobileNet\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(355, activation='softmax')(x)  # Adjust output neurons based on your classification task\n",
    "\n",
    "# Combine base model and custom layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate=1e-2, momentum=0.9, nesterov=True),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train your model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=1000,  # Adjust as needed\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Extract results from the final epoch\n",
    "final_epoch_results = {\n",
    "    'loss': history.history['loss'][-1],\n",
    "    'accuracy': history.history['accuracy'][-1],\n",
    "    'val_loss': history.history['val_loss'][-1],\n",
    "    'val_accuracy': history.history['val_accuracy'][-1]\n",
    "}\n",
    "\n",
    "# Print the final epoch results\n",
    "print(\"Final Epoch Results:\")\n",
    "print(final_epoch_results)\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy history\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on test data\n",
    "validation_generator.reset()  # Reset the generator to start from the beginning\n",
    "predictions = model.predict(validation_generator, steps=validation_generator.samples // batch_size + 1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(validation_generator.classes, predicted_classes)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "\n",
    "for i in range(355):  # Adjusted based on the number of classes\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "\n",
    "    precision_i = true_positives / (true_positives + false_positives) if true_positives + false_positives != 0 else 0\n",
    "    recall_i = true_positives / (true_positives + false_negatives) if true_positives + false_negatives != 0 else 0\n",
    "\n",
    "    precision.append(precision_i)\n",
    "    recall.append(recall_i)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    if precision_i + recall_i != 0:\n",
    "        f1_score_i = 2 * (precision_i * recall_i) / (precision_i + recall_i)\n",
    "    else:\n",
    "        f1_score_i = 0\n",
    "\n",
    "    f1_score.append(f1_score_i)\n",
    "\n",
    "# Calculate average precision, recall, and F1 score\n",
    "avg_precision = np.mean(precision)\n",
    "avg_recall = np.mean(recall)\n",
    "avg_f1_score = np.mean(f1_score)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1 Score:\", avg_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd051c3-269c-4f0c-b36a-65045e91025c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
